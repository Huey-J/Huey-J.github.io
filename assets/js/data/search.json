[ { "title": "성능 평가 후기2 Transaction Pool, Connection Pool 성능 튜닝", "url": "/posts/ConnectionPool-TransactionPool/", "categories": "backend, spring", "tags": "spring, java, transaction pool, connection pool, 성능 튜닝", "date": "2024-02-15 13:00:00 +0900", "snippet": "“서버 성능을 올려야겠는데…”위 얘기를 들으면 뭐부터 생각나시나요? 인스턴스의 티어를 올려요! (Scale-Up) 서버를 늘려요! (Scale-out) 캐싱을 적용해요 등등..다양한 방법이 있습니다. 자 그럼 단순하게 Scale-Up, Scale-Out으로 서버의 성능이 쭉쭉 늘까요? 돈이 드는 만큼 한 번 확인해 봅시다.1. 단순 EC2 Scale Up기대 값 인스턴스 이름 온디맨드 시간당 요금 vCPU 메모리 스토리지 네트워크 성능 t3.small 0.0208 USD 2 2GiB EBS 전용 최대 5기가비트 t3.medium 0.0416 USD 2 4GiB EBS 전용 최대 5기가비트 t3.large 0.0832 USD 2 8GiB EBS 전용 최대 5기가비트 t3.xlarge 0.1664 USD 4 16GiB EBS 전용 최대 5기가비트 t3.2xlarge 0.3328 USD 8 32GiB EBS 전용 최대 5기가비트 위의 표는 AWS EC2 서울 리전의 가격과 스펙을 나열한 표입니다.AWS에서 단순히 인스턴스의 성능만 올려봅시다. 가격이 2배씩 증가하니까 성능도 2배씩 올랐으면 좋겠네요!실제 값 DB Only : JPA를 활용해 DB 조회를 수행하며, 대부분 DB I/O 작업으로 이루어져 있는 API. CPU Only : 복잡한 연산 로직 수행하며, 대부분 CPU 작업으로 이루어져 있는 API. ALL : 위의 두 작업을 같이 수행하는 API.인스턴스의 티어를 올리면서 측정한 TPS입니다. 아래와 같이 분석할 수 있습니다. 가격은 2배씩 증가하지만 성능은 가격만큼 오르지 않는다. (오차 범위 이내) CPU 코어수에 따라 Cpu와 관련된 작업(Cpu Only, ALL)이 오르는 것을 볼 수 있다.2. 단순 RDS Scale-Up기대 값 인스턴스 이름 (MySql) 시간당 요금 코어 개수 vCPU* 메모리(GiB) 네트워크 성능(Gbps) db.t3.small 0.052 USD 1 2 2 최대 5 db.t3.medium 0.104 USD 1 2 4 최대 5 db.t3.large 0.208 USD 1 2 8 최대 5 위의 표는 AWS RDS 서울 리전의 가격과 스펙을 나열한 표입니다.이번에는 반대로 EC2의 티어는 고정하고 RDS만 스펙을 올려봅시다.여기서도 가격이 2배씩 증가하는데 DB관련 작업은 2배씩 오를까요?실제 값 DB Only : JPA를 활용해 DB 조회를 수행하며, 대부분 DB I/O 작업으로 이루어져 있는 API. CPU Only : 복잡한 연산 로직 수행하며, 대부분 CPU 작업으로 이루어져 있는 API. ALL : 위의 두 작업을 같이 수행하는 API.여기서는 아래와 같이 분석할 수 있겠네요. DB 관련 작업(DB Only)은 성능이 조금씩 오르긴 하지만 가격에 비하면 미미하다.3. 왜 그럴까? 리소스 사용량 확인성능이 조금씩 오르긴 하지만 뭔가 제대로 오른 스펙을 활용하고 있지 않는다는 느낌이 듭니다. 그럼 리소스 사용량을 확인해 볼까요?아래는 AWS Cloud Watch로 확인한 각 인스턴스의 CPU 사용량 그래프입니다. EC2 : t3.2xlarge / RDS : db.t3.medium 사용량위의 표에서 볼 수 있는 것은 다음과 같습니다. DB Only 작업에서 RDS의 성능을 전부 사용하지 않고 있음. (RDS CPU 사용량 약 45%) CPU Only 작업에서 EC2의 성능을 전부 사용하고 있음. (EC2 CPU 사용량 약 99%) “Spring Boot의 기본 설정으로는 EC2의 성능을 전부 활용할 수 있지만, RDS의 성능을 전부 활용하지 않는다.”4. 원인 분석해당 글에서 얘기하고자 하는 내용은 Tomcat의 Thread Pool 과 Hikari Connection Pool 입니다.그리고 먼저 스포하자면 Spring Boot 의 기본 설정은 아래와 같기 때문에 위와 같은 결과가 나온 것입니다. Thread Pool 기본 값 : 충분한 스레드 풀을 설정하여 서버의 성능을 최대한 사용할 수 있도록 함. Connection Pool 기본 값 : RDS의 성능을 전부 활용하지 못하도록 제한하고 있음.그럼 Thread Pool, Connection Pool이 뭐길레 성능에 영향을 미칠까요? 들어가기 전 설명: Pool 이란? 컴퓨터 과학에서의 풀은 자원을 사용하는 시점에 메모리에 올리고, 사용을 완료한 이후 메모리에서 해제하는 대신 이미 사용할 준비가 된 자원을 메모리 위에 일정량 미리 생성해둔 자원의 집합이다. 자원이 필요할 경우 새로 자원을 생성하는 대신 풀에서 꺼내 사용하고, 사용이 완료된 경우 자원을 해제하는 대신 풀에 다시 반환하는 형태로 사용한다. 미리 자원을 생성해두면 어떤 이점을 얻게 될까? 자원을 필요할 때 자원의 생성, 파괴 비용을 절약할 수 있다. 즉, 오버헤드(overhead)를 줄일 수 있다. 데이터베이스 혹은 소켓 등은 상대방과 연결하기 위해 꽤 오랜 시간이 걸린다. 미리 커넥션을 생성해두고, 이 커넥션을 재사용하는 방식을 사용하면 애플리케이션의 성능을 개선할 수 있을 것이다.5-1. 서버 성능 올리기 :: Tomcat Thread Pool우선, 이전의 측정 값을 보면 다음과 같이 정리할 수 있습니다. Spring Boot의 기본 설정으로는 EC2의 CPU 사용량이 99% 까지 올라갔다. 즉, 기본 설정은 EC2의 성능을 제한하지 않는 것으로 봐도 무방하다. 서버의 코어 수가 증가함에 따라 Cpu와 관련된 작업(Cpu Only, ALL)의 성능이 향상되었다.-&gt; CPU 작업은 스레드를 통해 이뤄지며, Spring Boot에서는 Tomcat의 Thread Pool을 통해 스레드를 관리한다.Tomcat Thread Pool 이란? 필요한 스레드를 스레드 풀에 보관하고 관리한다. min-spare ~ max 스레드 풀에 생성 가능한 스레드의 최대치를 관리한다. max 스레드가 필요하면 이미 생성되어있는 스레드를 스레드 풀에서 꺼내 사용한다. 사용을 종료하면 스레드 풀에 해당 스레드를 반납한다. 최대 스레드가 모두 사용중이어서 스레드 풀에 스레드가 없다면 기다리는 요청은 거절하거나 특정 숫자만큼만 대기하도록 설정할 수 있다.Default Settingserver: tomcat: threads: max: 200 # 생성할 수 있는 thread의 총 개수 min-spare: 10 # 항상 활성화 되어있는(idle) thread의 개수 max-connections: 8192 # 수립가능한 connection의 총 개수 accept-count: 100 # 작업큐의 사이즈 connection-timeout: 20000 # timeout 판단 기준 시간, 20초→ 10개의 스레드를 항상 유지하고, 최대 200개 까지 생성될 수 있다.즉, 많아봤자 8코어 16코어였던 코어 수에 비해 최대 스레드 수가 충분히 많기(200) 때문에 서버의 CPU 성능을 99% 사용할 수 있었고, 코어 수 만큼 성능이 증가할 수 있었던 것이죠!Custom Setting그렇다면 CPU의 최대 사용량을 Thread Pool의 개수를 낮춤으로서 제어할 수 있지 않을까요? 바로 테스트해 봅시다. 설정 값 : 최대 스레드 수를 EC2(t3.2xlarge) 8코어의 절반인 4 설정. 기대 값 : CPU의 사용량이 약 50프로가 넘지 않고 성능도 그만큼 낮아질 것으로 기대.server: tomcat: threads: max: 4 min-spare: 2성능 비교EC2(t3.2xlarge) + RDS(db.t3.medium) 결과.-&gt; 예상한대로 CPU 사용량과 성능 제한이 정상적으로 이뤄진 걸 볼 수 있습니다. 하지만 CPU 작업 뿐만 아니라 DB 작업도 성능이 저하된 것을 볼 수 있죠.5-2. 서버 성능 올리기 :: Hikari Connection PoolRDS의 티어별 성능 측정값을 보면 다음과 같이 정리할 수 있습니다. RDS의 티어를 올려도 성능의 증가 폭이 매우 적다. 즉, 성능의 제한 값이 존재하는 것으로 유추할 수 있다.RDS(MySql) Connection 이란? DB 연결은 TCP로 이뤄지므로 비용이 많이 든다. → Connection Pool의 필요성 따라서 WAS(웹 컨테이너)가 실행될 때 DB연결을 위해 미리 일정수의 connection 객체를 만들어 Pool에 담아 둔다. 클라이언트의 요청이 발생하면 Pool에서 생성되어 있는 Connection 객체를 넘겨준다. 처리가 끝나면 Connection 객체를 다시 Pool에 보관한다.Default Settingspring: datasource: hikari: maximum-pool-size: 10 # Connection Pool에 유지 가능한 최대 커넥션 개수 minimum-idle: 10 # Connection Pool에 유지 가능한 최소 커넥션 개수 connection-timeout: 30000 # Pool에서 Connection을 구할 때 대기시간 idle-timeout: 600000 # Connection이 Poll에서 유휴상태(사용하지 않는 상태)로 남을 수 있는 최대 시간 max-lifetime: 1800000 # Connection의 최대 유지 가능 시간→ 항상 10개의 connection을 유지하고 더 늘어나지 않도록 한다.즉, RDS의 성능이 아무리 좋아도 DB와 통신할 때 사용할 Connection 수가 10개 이상으로 증가하지 않기 때문에 서버의 성능이 오르지 않았던 것입니다.그럼 이 설정값을 올려주면 성능도 같이 올라갈까요?Custom Setting 우선 사용중인 RDS에서 최대로 지원할 수 있는 Connection 수를 확인해 봅시다. (db.t3.medium)-- db.t3.medium 예시mysql&gt; show variables like 'max_connections';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 143 |+-----------------+-------+1 row in set (0.01 sec) 해당 값보다 크게 설정할 경우 JDBCConnectionException: Unable to acquire JDBC Connection 발생 확인한 값을 바탕으로 application.yml 파일에서 hikari cp 설정 변경해 줍시다.# 간단 예시spring: datasource: hikari: maximum-pool-size: 130 minimum-idle: 100성능 비교 EC2(t3.2xlarge) + RDS(db.t3.medium) 결과. DB 관련 성능(DB Only, ALL)이 크게 증가한 것을 볼 수 있음.리소스 사용량RDS 커넥션 수RDS CPU 사용량 RDS의 커넥션 수가 설정한 만큼 생성되는 것을 볼 수 있음. RDS의 CPU를 거의 최대로 사용하고 있는 것을 볼 수 있음.Thread Pool과 Connection Pool에 대해 좀 알게 되었으니 이제 같이 적용해 볼까요?!6. 같이 설정Custom Setting EC2의 8코어를 전부 사용할 수 있도록 Max Thread 수를 8로 설정. RDS의 성능을 전부 사용할 수 있도록 Max Connection 수를 130으로 설정.server: tomcat: threads: max: 8 min-spare: 4spring: datasource: hikari: maximum-pool-size: 130 minimum-idle: 100성능 비교RDS CPU 사용량EC2 CPU 사용량 CPU만 사용하는 작업(CPU Only)의 경우 EC2의 성능은 충분히 사용하고 있음. DB와 관련된 작업(DB Only, ALL)의 경우 리소스를 충분히 활용하고 있지 않음.즉, CPU는 예상했던 대로 성능 향상이 있었지만, DB 관련 성능은 Connnection Pool만 설정했을 때 보다 낮아졌을 뿐만 아니라 기본 설정과 오차 범위 내로 비슷한 수치를 보여주고 있습니다.왜 그런지는 아래 Spring의 커넥션 관련 로그를 보면 알 수 있는데요.Connection Pool 사용량 로그Spring Boot의 로그를 보면 Connection을 8개만 사용하고 있습니다. (= 설정한 스레드 수 만큼 사용)흐으음 이건 또 왜 그럴까요..이유 분석결론부터 말하자면, DB I/O 작업으로 인해 스레드가 쉬게 되는 시간을 고려하지 않았기 때문입니다.JVM Thread 상태 Thread.State.NEW : 객체 상태스레드가 생성되었지만 아직 시작되지 않은 상태 Thread.State.RUNNABLE : 실행 대기스레드가 실행 가능한 상태 Thread.State.BLOCKED : 일시 정지스레드가 일시적으로 중단된 상태 Thread.State.WAITING : 일시 정지스레드가 다른 스레드의 특정 작업 완료를 기다리는 상태 Thread.State.TIMED_WAITING : 일시 정지스레드가 일정 시간 동안 기다리는 상태 Thread.State.TERMINATED : 종료스레드가 실행을 완료한 상태정리하자면, 스프링이 JPA 메소드를 호출하면 해당 스레드는 블로킹 상태가 됩니다. 그리고 블로킹 상태에서는 스레드 풀에 의해 다른 작업을 수행하도록 해서 CPU를 효율적으로 사용하는 것이죠. 8개의 스레드가 DB 요청을 하고 기다리는 동안 CPU 코어는 다른 스레드 작업을 할 수 있다.하지만 스레드 풀에 남아있는 스레드가 없기 때문에 기다릴 수 밖에 없게 되었다.따라서 EC2, RDS 모두 리소스를 전부 활용하지 못하는 상황이 발생하여 성능이 저하된 것이다.7. 결론이제 결론을 내봅시다! 그렇다면 적절한 설정 값은 무엇일까요?적정 Thread Pool스레드를 많이 생성해둔다고 그 스레드를 다 사용할 수 있는 것은 아닙니다. Default 설정에서 볼 수 있었죠. 그리고 쓸데없이 스레드를 많이 생성한다면 생성하는 데에 드는 자원과 비용이 낭비되기도 하죠.물론 그렇다고 스레드를 부족하게 만들어둔다면 CPU 사용률이 낮아지게 되고 성능에 제한이 걸리는 상황이 발생합니다.그래서 적정 스레드 풀을 계산하는 공식이 있습니다. 스레드 풀 적정 크기 = cpu 코어 개수 * (1 / cpu 사용시간 비율) I/O 작업 등으로 Thread가 블로킹 되어 있는 시간을 효율적으로 사용하기 위해 나온 공식입니다. CPU의 작업이 많다면 코어 수와 가깝게, I/O 작업이 많다면 코어 수 보다 많이 설정하게 됩니다.스레드 풀 크기는 적정 크기를 정확하게 계산하는 것 보다, 너무 부족하게 세팅하여 cpu가 놀고있거나 너무 과도하게 크게 세팅하여 더 많은 자원(Context Switch)을 불필요하게 사용하지 않게 만드는 것이 더 중요하다고 합니다.적정 Connection PoolConnection Pool은 서버 개수와 DB 인스턴스의 성능을 고려해서 결정해야 합니다. 하지만 최소한의 개수는 필요한데 그 공식은 아래와 같습니다. 커넥션 풀 적정 크기 = 전체 Thread 개수 * (하나의 Task에서 동시에 필요한 Connection 수 - 1) + 1Connection Pool은 우선 Thread Pool 보다는 많이 설정해야 합니다. 데드락에 걸릴 수 있기 때문인데 자세한건 여기에서 볼 수 있습니다. (아래 공식에서 +1이 붙은 이유)그리고 만약 Thread Pool의 크기보다 Connection Pool의 크기가 훨씬 더 크면 메모리 상에서 남은 Connection은 작업을 하지 못하고 놀게 되기에, 실직적으로 메모리만 차지하게 됩니다.마치며적절한 Thread Pool과 Connection Pool을 설정하는건 단순히 공식으로 구하긴 어렵습니다. 기능마다, 환경마다 다르기 때문이죠. 하지만 위에서 볼 수 있듯이 서버 성능에 매우 큰 영향을 미치며 잘못 설정하면 치명적인 오류가 발생하기도 합니다.결론은 잘 알고 쓰자!" }, { "title": "성능 평가 후기", "url": "/posts/%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80-%ED%9B%84%EA%B8%B0/", "categories": "backend, spring", "tags": "spring, java, jmeter, 후기, 성능 튜닝", "date": "2023-09-30 13:00:00 +0900", "snippet": "👀 성능 평가? 왜 하게 되었나?9월에는 제가 속한 신규 플랫폼 팀에 큰 이벤트가 있었습니다. 바로 이름부터 무시무시한 플랫폼 성능 평가죠.성능..뭐시기요..?성능 평가… TPS… 전부 해 본적이 없는 것들이라 막막했지만 또 한편으로는 굉장히 설랬습니다.새로운 도전이라는 생각에 말이죠. ㅎㅎ결과적으로 무사히 통과하였고 성대한(?) 파티까지 즐겼기에 후기를 남겨보려고 합니다.🧐 성능 평가 준비!요구사항저희 신규 플랫폼은 거래 데이터를 블록체인 원장에 기록하고 조회하는 기능을 제공하고 있습니다.성능 평가에서는 다양한 기준이 있었지만, 제가 주로 담당한 부분은 아래 2개의 과제였습니다. 블록체인 입력 처리 성능 40TPS 이상 블록체인 조회 처리 성능 200TPS 이상TPS가 엄청나게 높진 않지만 DB 읽기/쓰기와 요청 값 검증, 블록체인 서버 연동 등 다양한 과정을 거치기 때문에 이를 만족시키기 위해서는 갈 길이 멀어 보였죠.사전 데이터 준비여기서 입력과 조회 모두 사전에 데이터를 준비해야 했기 때문에, 이를 위한 작업이 필요했습니다.특히 입력의 경우 API 호출 개수만큼 세금계산서 데이터를 준비해야 했죠.따라서 저는 개수가 몇개 안되는 유저나 회사 같은 데이터들은 쿼리문으로,천 단위의 개수를 가진 세금계산서 데이터는 procedure 코드를 작성해 DB에 넣어주었습니다.인프라 아키텍처저희는 AWS를 사용하고 있기 때문에, ALB와 인스턴스 그룹을 사용하여 Scale Out을 통해 성능을 개선하기로 했습니다.물리적인 서버의 개수로 TPS 수치를 점진적으로 올릴 수 있기 때문이었죠.오토 스케일링은 오버 엔지니어링이라고 판단하여 적용하지 않았습니다.대략적인 인프라 구조도위의 구조도는 블록체인 입력을 예를 들어 설명한 것입니다.블록체인 입력 요청이 들어오면 플랫폼 서버는 DB에서 조회한 값과 요청 값을 통해 권한 검증 등의 비즈니스 로직을 수행합니다.이후 블록체인 서버에 입력을 요청한 후 응답을 받아 다시 DB에 저장합니다.꽤나 무거운 작업이죠.블록체인 조회 요청은 위 구조도에서 4번과 5번 과정인 Set을 제외한 구조라고 생각하시면 됩니다.성능 측정 툴과 첫 측정 값TPS를 측정하기 위해서 다양한 툴이 있지만, 저희는 JMeter를 사용했습니다.가장 많이 사용되고 그 만큼 자료도 많았기 때문이죠.JMeter를 사용하여 EC2 하나와 RDS 하나를 생성하여 성능을 측정했을 때 아래와 같은 결과를 얻었습니다. 블록체인 입력: 26.5 TPS 블록체인 조회: 44.4 TPS입력은 기준 값을 통과했지만 조회 성능은 예상했던 것 보다 턱없이 부족했습니다.흐으음… 이제 작업 시작이죠!💪 성능 개선EC2 Scale Out 결과AWS Load Balancer로 Scale Out을 구축해 놓았기 때문에 EC2를 간단히 늘리면서 성능을 측정해 보았습니다.EC2를 두개로 올렸을 때 약 2배, 3개로 올렸을 때 약 3배의 성능 향상을 보여줬죠.따라서 EC2를 총 5개 이상으로 올리면(45 x 5 = 225) 될 거라는 안일한 생각을 하게 되었습니다. (슬픈 예감은 틀린적이 없..ㄷr..)EC2 성능 올리기Scale Out의 희소식을 팀에 공유하고 저는 EC2 하나의 TPS를 올리는 방법을 고민해 보았습니다.찾아보니 Thread Pool과 Connection Pool을 적절히 설정해 주면 성능을 올릴 수 있다는 글을 보게 되었죠.해당 작업과 RDS의 Scale Up 등을 통해서 EC2 하나, RDS 하나의 성능을 아래와 같이 끌어올릴 수 있었습니다. 블록체인 입력: 26.5 TPS -&gt; 43.0 TPS 블록체인 조회: 44.4 TPS -&gt; 109.5 TPS자세한건 다음 포스트에서 다루도록 하겠습니다 :)🤯 이제 마무리만 지으면 될…줄 알았지?준비는 끝났다고 생각하고 리허설 전에 EC2 Scale Out을 통해 TPS 성능을 충족시키려고 했습니다.그러나… EC2를 3개, 5개, …, 8개까지.. 아무리 올려도 200TPS 근처에서 올라가질 않았습니다.조회 성능 기준인 200TPS를 안정적으로 넘어서지 못하는 것이죠.으아아아악로드 밸런서도 확인해 보고, RDS나 EC2의 로그도 확인해 봤지만 도저히 원인을 찾을 수 없었습니다.찾았다! 병목 현상의 원인다양한 삽질 끝에 혹시..? 라는 생각에 블록체인 서버의 TPS를 확인해 보았고 200TPS가 나왔습니다.블록체인 서버에서 병목현상이 발생하고 있었던 것이죠. (분명 블록체인 서버 문서에는 훨씬 높은 TPS를 지원한다고 했었는데 말입니다?)병목 현상 구조도블록체인과의 통신 과정이 동기식으로 동작하고 있었기 때문에 블록체인 서버의 TPS가 낮아지면 플랫폼 서버의 TPS도 낮아지게 되었던 것이죠.이를 해결하기 위해서 블록체인 서버에 대한 조회 응답값을 캐싱하는 방법이 있었고 팀장님과 얘기한 후 이를 적용하기로 했습니다.캐싱을 적용하니 당연히 TPS는 기존 값을 훌쩍 넘어서게 되었고, 덕분에 성능 평가를 성공적으로 마칠 수 있었습니다.🥳 후기성능 평가 결과를 받고 아웃백에서 축하 파티를 했습니다. 점심 회식은 못 참지..Jmeter도 처음 해보고 Thread Pool 등등 다양한 공부와 삽질도 많이 해서 덕분에 크게 성장을 했다고 생각합니다.다음 포스팅에서는 위에서 예고했던 대로 EC2의 성능을 올리기 위해 적용한 방법들에 대해 다루도록 하겠습니다. :)To Be Continued…" }, { "title": "SonarCloud로 코드 분석하기", "url": "/posts/sonarcloud-%EC%A0%81%EC%9A%A9/", "categories": "backend, spring", "tags": "spring, java, github actions, sonar cloud", "date": "2023-08-03 13:00:00 +0900", "snippet": "1. 목표SonarCloud를 이용하여 코드의 품질과 테스트 커버리지 등을 측정하고, Github Actions와 연동하여 PR 시 정적 분석 결과를 코멘트로 남겨주도록 설정한다. 예제에서 다룬 코드는 여기서 확인할 수 있습니다.2. SonarCloud 란SonarCloud는 정적 분석 툴인 SonarQube의 SaaS 형태입니다.여기서 정적 분석이란 애플리케이션을 실제 실행하지 않고 분석하는 것을 의미하며, 반대로는 동적 분석이 있습니다.간단하게 얘기하면 제 코드를 보고 버그나 취약점, 냄새나는(?) 코드를 찾아주는 배은망덕한 고마운 친구죠 :)PR에 코멘트도 달아주고, Quality Gates와 Github 설정을 연계해 머지에 대한 제약도 걸 수 있습니다.그리고 뭐니 뭐니 해도 SonarCloud를 사용해야 할 가장 큰 이유는 분석 대상이 Public Repository인 경우 ‘무료’이기 떄문입니다! ㅎㅎ공짜는 못 참지 크흠 흠… SonarCloud 지표 Bugs(Reliability): 잠재적인 버그 혹은 실행시간에 예상되는 동작을 하지 않는 코드 Vulnerabilities(Security): 보안상 이슈가 있는 코드 Code Smells(Maintainability): 심각한 이슈는 아니지만 유지관리를 위해 개선하면 좋을 코드 Coverage: 테스트 커버리지 Duplications: 코드 중복 Security Hotspots: 취약성이 존재하는지 여부를 평가하기 위해 수동 검토가 필요한 코드 3. 기본 연동가장 간단한 방법입니다. 준비물은 분석하고자 하는 Public Repository만 있으면 되고, 이것을 SonarCloud에 등록하여 default 브랜치를 분석합니다.프로젝트 연결SonarCloud 에서 깃허브 계정으로 로그인 후 organization을 연결해 줍니다.1.우측 상단 create new organization -&gt; Import an organization from Github2.Organization 선택 후 SonarCloud 에 분석하고자 하는 Repository를 선택해 줍니다.3.free plan을 선택하고 넘어갑시다.(private repo는 유료) 여기서 설정하는 값들은 추후 언제든지 변경 가능하니 참고 해주세요 :)이후 분석할 repository를 다시 한번 선택하면 SonarCloud에 프로젝트가 생긴 걸 볼 수 있습니다.분석 이력을 보면 아래 사진처럼 첫 분석이 Success로 잘 수행된 것을 확인할 수 있습니다!PR 코멘트 확인간단하게 SonarCloud에 등록만 해준 것 뿐인데 아래 PR처럼 코멘트도 자동으로 달아줍니다.https://github.com/Huey-J/sonarcloud-example/pull/1짜자잔~이는 Automatic Analysis 라는 설정이 기본적으로 켜져 있기 때문인데요! 아래에서 추가로 알아보는 걸로 하고 일단 넘어갑시다.다시 PR 코멘트로 돌아와 내용을 보면 Bug는 없지만 Code Smell이 하나 있는걸 볼 수 있는데 SonarCloud에서 한번 확인해 볼까요?사용하지 않는 import문이 있으니 삭제하라고 권고하고 있습니다. 말 그대로 냄새 나는 코드군요. 🫣여기까지가 가장 간단하게 SonarCloud를 연동하는 방법이었습니다. 굉장히 간단하죠? 하지만 뭔가 많이 부족한 것 같은데…3. 테스트 커버리지 적용위에서 봤던 PR 코멘트를 보면 No Coverage information라는 문구를 볼 수 있습니다.말 그대로 테스트 코드의 커버리지 정보가 없다는 것인데요. 정적 분석에 커버리지가 없다니! 얼른 추가해 줍시다.CI 방식으로 전환SonarCloud는 자체적으로 커버리지를 분석하지는 않고, jacoco와 같은 테스트 커버리지 툴이 만든 보고서를 이용하여 보여주는 방식을 사용합니다.즉, 커버리지 적용을 위해서는 jacoco가 필요하고, 보고서를 전달하기 위해 현재의 Auto 방식이 아닌 CI 방식으로 변경해야 하죠.1.좌측 하단의 Analysis Method 메뉴로 들어가 Automatic Analysis를 끄고, 우리가 사용할 github action을 선택해 줍니다.2.그리고 굉장히 친절하게 알려주는 설정 방법을 통해 Github Repository의 Secret을 추가해 줍니다.3.workflow와 build.gradle을 수정하는데, 아래와 같이 Jacoco와 xml report를 생성하도록 설정합니다.JDK 버전에 주의합시다!plugins { id 'jacoco' id \"org.sonarqube\" version \"4.2.1.3168\"}sonar { properties { property \"sonar.projectKey\", \"Huey-J_sonarcloud-example\" property \"sonar.organization\", \"huey-j\" property \"sonar.host.url\", \"https://sonarcloud.io\" }}jacocoTestReport { reports { xml.enabled true }}name: SonarCloudon: push: branches: - main pull_request: types: [opened, synchronize, reopened]jobs: build: name: Build and analyze runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 with: fetch-depth: 0 # Shallow clones should be disabled for a better relevancy of analysis - name: Set up JDK 17 uses: actions/setup-java@v3 with: java-version: 17 # JDK 버전 distribution: 'zulu' # Alternative distribution options are available - name: Cache SonarCloud packages uses: actions/cache@v3 with: path: ~/.sonar/cache key: $-sonar restore-keys: $-sonar - name: Cache Gradle packages uses: actions/cache@v3 with: path: ~/.gradle/caches key: $-gradle-$ restore-keys: $-gradle - name: Build and analyze env: GITHUB_TOKEN: $ # Needed to get PR information, if any SONAR_TOKEN: $ run: ./gradlew build jacocoTestReport sonar --info # jacocoTestReport 추가위와 같이 수정 후 커밋, 푸시 하면 Github Actions가 정상적으로 수행되고, 테스트 커버리지가 잘 반영되는 것을 볼 수 있습니다.이후 PR 코멘트에도 정상적으로 커버리지가 적용되는걸 확인할 수 있습니다.https://github.com/Huey-J/sonarcloud-example/pull/24. 세부 설정 추가SonarCloud PR approve 조건 설정SonarCloud Bot이 PR에 코멘트를 남길 때 approve, reject에 대한 조건이 있는데, 이를 Quality Gate라 부릅니다. 요걸 수정해 봅시다.Organization -&gt; Quality Gates 에 들어가면 해당 Organization에 속한 통과 조건들이 있습니다.위 이미지에서는 Default 설정을 복사하여 Coverage 통과 조건만 80에서 60으로 낮추었습니다.그리고 맨 아래에 있는 Projects에 해당 Quality Gate를 적용할 프로젝트를 체크하면 이후 검증 작업부터 적용이 됩니다.PR Merge 조건에 SonarCloud 연동깃허브에서 SonarCloud 조건을 통과하지 못할 경우 Merge가 안되도록 설정할 수 있습니다.Settings -&gt; Branches -&gt; Branch protection rule 머지 조건으로 Sonar Cloud를 추가해 줍니다.5. 마무리이번 글에서는 SonarCloud를 연동하여 정적 분석을 작업 프로세스에 추가하였습니다.덕분에 코드의 품질과 테스트 커버리지에 대해 좀 더 고민하며 개발할 수 있지 않을까 라는 자그마한 기대를 해 봅니다. ㅎㅎ테스트 커버리지를 적용하면서 build.yml 마지막 줄에 jacocoTestReport를 추가하지 않아 커버리지 적용이 안돼서 삽질한 건 안비밀..References https://docs.sonarcloud.io/enriching/test-coverage/java-test-coverage/ https://community.sonarsource.com/t/jacoco-import-troubleshooting/35755 https://hyeon9mak.github.io/sonarcloud-trouble-shooting/" }, { "title": "트러블 슈팅 - querydsl 문제", "url": "/posts/querydsl-%ED%8A%B8%EB%9F%AC%EB%B8%94%EC%8A%88%ED%8C%85/", "categories": "backend, spring", "tags": "spring, java, querydsl, 트러블슈팅", "date": "2023-05-13 13:00:00 +0900", "snippet": " 회사에서 진행한 작업이기 때문에 실제 코드가 아닌 예시 코드로 적겠습니다.상황엔티티 상황간단한 예시로 가게(Shop)와 해당 가게에서 파는 물건(Goods)이 각각 엔티티로 있다고 하겠습니다.@Entitypublic class shop { @Id private Long id; private String name; private String ownerName;}@Entitypublic class goods { @Id private Long id; private String name; private boolean activated; private int price; @ManyToOne private Shop shop;}요구 사항구현해야 할 기능의 요구사항은 아래와 같습니다. Shop의 목록을 조회해야 하며, Paging 처리가 필요하다. 프론트 요청에 따라 조건이 달라져야 한다. 즉, 동적 쿼리로 구현해야 한다. 해당 Shop의 Goods 중, 프론트에서 요청한 조건에 부합하고 goods.activated=true인 상품의 총액을 반환해야 한다. 조건에 부합하는 Goods가 없거나 총액이 0 이하인 경우 반환할 Shop 목록에서 제외시켜야 한다.접근우선 쿼리문 부터 작성을 해 보았습니다.서브 쿼리를 사용한 쿼리문과, GROUP BY를 사용한 쿼리문, 총 두 개의 쿼리문을 작성하였습니다.두 쿼리는 동일한 값을 반환하지만, goods를 Limit 없이 조회하는 첫 번째 쿼리문 보다 두 번째 쿼리문이 효율적이었습니다.쿼리문 작성--- from 절에 sub query 이용SELECT sq.shop_id, sq.shop_name, sq.shop_owner_name, sq.total_goods_amountFROM ( SELECT shop.id AS shop_id, shop.name AS shop_name, shop.owner_name AS shop_owner_name, ( SELECT COALESCE(SUM(goods.price), 0) FROM goods WHERE goods.activated = true AND goods.shop_id = shop.id ) AS total_goods_amount ) AS sq-- JOIN 문 생략WHERE sq.total_goods_amount &gt; 0-- AND-- 동적 쿼리 생략...;--- group by 이용SELECT shop.id, shop.name, shop.owner_name, COALESCE(SUM(goods.price), 0) AS total_goods_amountFROM goods INNER JOIN shop ON goods.shop_id = shop.id-- JOIN 문 생략GROUP BY shop.id, shop.name, shop.owner_nameHAVING total_goods_amount &gt; 0-- WHERE 동적 쿼리 생략...; mysql 표준 GROUP BY 사용 규칙 GROUP BY는 GROUP BY에 정의한 내용(컬럼 또는 변형된 컬럼)만 SELECT절에 그대로 사용할 수 있다. GROUP BY에 정의하지 않은 컬럼을 SELECT절에서 사용하려면 반드시 집계함수 처리를 해야 한다. 구현JPQL, Native Query 등 방식은 여러 가지일 수 있지만, 동적 쿼리라는 요구사항에 가장 적합한 QueryDsl로 구현하고자 하였습니다.하지만 구현하는 과정에서 두 쿼리문 모두 문제가 발생하였습니다.문제 발생첫 번째 쿼리문 (sub query) ‘JPQL에서 서브쿼리는 WHERE, HAVING 절에서만 사용할 수 있습니다.’JPQL FROM 절 서브쿼리가 스펙상 불가능하다고 합니다. 따라서 개발하고자 한 Querydsl 에서도 불가능했습니다.두 번째 쿼리문 (group by) ‘when groupBy with two fields,fetchCount throw exception’https://github.com/querydsl/querydsl/issues/2504paging으로 반환하기 위해 fetchCount() 메소드를 사용했는데 에러가 발생했습니다.위의 깃허브 이슈를 보면 group by로 2개 이상의 컬럼을 걸어줄 경우 Count Query가 JPQL로의 변환이 실패된다고 합니다.해결간단하게 native query를 사용하면 되겠지만 동적 쿼리가 걸렸고, pagenation을 포기할 수도 없었습니다.고민 끝에 QueryDsl을 native query로 변환해주는 클래스를 추가하여 해결하였습니다.위 이슈에서 gudaoxuri 라는 분의 댓글에 jpaQuery를 serialize 하여 native query로 변경하고 카운트 쿼리와 실제 쿼리문을 만들어 줄 수 있다고 합니다.해당 코드와 https://myborn.tistory.com/26의 글을 참고했습니다.배운 점 요약 JPQL에서 서브쿼리는 WHERE, HAVING 절에서만 사용할 수 있음. QueryDsl에서 2개 이상의 group by를 사용했을 때, count query 변환에 오류가 발생함. QueryDsl도 native query로 변경할 수 있음." }, { "title": "스프링 서버의 세상 간단한 CI/CD 구축 방법 (with Docker, Github Actions, AWS EC2)", "url": "/posts/docker-cicd/", "categories": "데브옵스, 네트워크", "tags": "DevOps, Spring, AWS", "date": "2023-01-19 13:00:00 +0900", "snippet": "CI/CD는 처음하는 분들에게는 꽤 난이도가 높은 작업이라고 생각합니다.그래서 많은 방법 중에 제가 생각하는 가장 간단한 방법인 도커를 이용하여 CI/CD를 구축하는 것을 소개하고자 합니다.단계 별로 기본적인 CI를 구성하고, 도커허브에 자동으로 푸시한 이후, AWS에 접속하여, 배포하는 총 4단계로 나누어 진행하겠습니다.해당 방식의 가장 큰 장점은 쉽다!, 공짜다! 정도가 될 것 같습니다:)준비물준비물은 아래와 같습니다. 도커허브 계정 AWS 계정 Github 계정 AWS EC2 (ubuntu) Spring Boot 프로젝트그리고 저는 아래의 환경에서 작업하였습니다. Ubuntu Server 22.04 Gradle JDK 111. 기본 github action CI 설정우선 가장 간단하게 깃허브 main 브랜치에 푸시가 되었을 때 빌드를 수행하는 워크플로우를 추가해 봅시다.프로젝트 루트 폴더에서 .github/workflows/basic-ci.yml 파일을 추가하고 아래 내용을 입력해 줍니다.name: Basic CIon: push: branches: [ \"main\" ]jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 # build - name: Setup Java JDK uses: actions/setup-java@v1 with: java-version: 11 - name: Grant execute permission for gradlew run: chmod +x gradlew - name: Build with Gradle run: ./gradlew build 3-5 Lines : main 브랜치에 push 되었을 때 해당 CI가 시작된다. 9 Lines : 우분투 환경에서 실행된다. 15-18 Lines : JDK 버전은 11 20-21 Lines : gradlew의 권한을 변경한다. 23-24 Lines : gradlew를 통해 build 파일을 생성한다.해당 파일을 main브랜치에 푸시하면 github action탭에서 성공하는 것을 볼 수 있습니다.succeed basic cisucceed basic ci 22. 자동으로 도커 허브에 푸시이번에는 1번에서 빌드한 jar 파일을 도커에 넣고 도커허브에 푸시하는 것 까지 해보겠습니다.도커파일 생성루트 폴더에 Dockerfile을 생성하고 아래 내용을 입력해줍니다. (확장자 없이 그냥 만들면 됨)jar 파일을 컨테이너 안에 넣고 실행시킨다 라는 내용입니다.FROM openjdk:11EXPOSE 8080# The application's jar fileARG JAR_FILE=build/libs/demo-0.0.1-SNAPSHOT.jar# Add the application's jar to the containerADD ${JAR_FILE} demo.jar# Run the jar fileENTRYPOINT [\"java\", \"-jar\", \"/demo.jar\"]도커 허브 Repository 생성도커 허브에 로그인하고 Create Repository로 새 Repository를 만들어 줍니다.create docker hub repository 1create docker hub repository 2도커허브 토큰 생성깃허브 액션에서 도커 허브에 접속할 때 사용할 토큰을 발급받아야 합니다.Account Settings - Security - New Access Tokencreate docker hub tokengithub secret 추가public repo라면 비밀번호를 숨길 필요가 있으므로 github secret에 아이디와 repository, 발급받은 토큰을 등록합니다.깃허브 프로젝트 - Settings - Secrets And Variable - Actions - New Repository Secretcreate docker hub github secret워크플로우 추가이제 도커 허브에 푸시를 하기 위한 준비는 끝났습니다. 이제 해당 작업을 워크플로우에 추가해 줍시다.기존에 작성되어 있는 부분 아래에 추가합니다. # docker push - name: Get current date id: date run: echo \"::set-output name=date::$(date +'%Y-%m-%d')\" - name: Log in to Docker Hub uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 with: username: ${ secrets.DOCKERHUB_ID } password: ${ secrets.DOCKERHUB_TOKEN } - name: Extract metadata (tags, labels) for Docker id: meta uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38 with: images: ${ secrets.DOCKERHUB_REPO } - name: Build and push Docker image uses: docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc with: context: . push: true tags: ${ steps.meta.outputs.tags }-${ steps.date.outputs.date } labels: ${ steps.meta.outputs.labels } 2-4 Lines : 도커 태그로 빌드 날짜를 저장하기 위해 현재 날짜 데이터를 불러온다. 6-10 Lines : 도커 허브에서 발급받은 토큰을 이용해 로그인한다. 12-16 Lines : 도커의 메타정보를 추출한다. 18-24 Lines : 도커 허브에 푸시한다.succeed docker push ci3. AWS 접속도커 허브에 빌드파일을 푸시했으니 이제 AWS에서 해당 이미지를 가져와 실행시켜주면 되겠죠.그 전에 AWS에 먼저 접속을 해봅시다.github secret 추가AWS 접속 정보 역시 숨길 필요가 있으므로 github secret에 AWS EC2의 퍼블릭 IPv4 DNS와 pem키를 등록해줍니다.여기서 pem키는 에디터로 열었을 때 나오는 문자들을 넣어주면 됩니다.aws ip address워크플로우 추가기존에 작성되어 있는 부분 아래에 추가해 줍니다. # server test - name: Deploy uses: appleboy/ssh-action@master with: host: $ # EC2 인스턴스 퍼블릭 DNS username: ubuntu key: $ # pem 키 script: | touch hello.txt echo \"hello world\" &gt; hello.txt EC2에 접속하여 루트 폴더에 hello.txt 파일을 생성하고 “hello world”를 저장한다.EC2에 접속해서 hello.txt가 생겼고, 안에 “hello world”가 입력되어 있다면 성공입니다.4. 도커 pull &amp; run이제 접속한 EC2에서 도커 허브에 푸시한 이미지를 가져와 실행만 시켜주면 끝입니다!AWS 도커 설치EC2에 도커를 설치해 줍시다. 해당 내용은 공식 문서를 참고해 주세요.도커 권한 설정설치 후 sudo 없이 docker ps 명령어를 입력했을 때 권한 오류가 발생한다면 아래 명령어를 입력합니다.sudo chmod 666 /var/run/docker.sockRef : https://kyungyeon.dev/trouble-shooting/2워크플로우 추가드디어 마지막 워크플로우입니다. 3번에서 추가했던 워크플로우를 아래와 같이 수정해 줍니다. # docker run in server - name: Deploy uses: appleboy/ssh-action@master with: host: $ # EC2 인스턴스 퍼블릭 DNS username: ubuntu key: $ # pem 키 script: | docker pull $-$ docker stop demo docker rm demo docker run --restart always -d -p 80:8080 --name demo $-$ EC2에 접속하여 도커 이미지를 pull 하고 80번 포트로 demo라는 이름으로 실행한다.이제 배포된 서버의 IP주소로 접속해보면 반가운(?) 404페이지가 뜨는 걸 볼 수 있습니다:)404 page최종 워크플로우 파일.github/workflows/basic-ci.ymlname: Basic CIon: push: branches: [ \"main\" ]jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 # build - name: Setup Java JDK uses: actions/setup-java@v1 with: java-version: 11 - name: Grant execute permission for gradlew run: chmod +x gradlew - name: Build with Gradle run: ./gradlew build # docker push - name: Get current date id: date run: echo \"::set-output name=date::$(date +'%Y-%m-%d')\" - name: Log in to Docker Hub uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 with: username: ${ secrets.DOCKERHUB_ID } password: ${ secrets.DOCKERHUB_TOKEN } - name: Extract metadata (tags, labels) for Docker id: meta uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38 with: images: ${ secrets.DOCKERHUB_REPO } - name: Build and push Docker image uses: docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc with: context: . push: true tags: ${ steps.meta.outputs.tags }-${ steps.date.outputs.date } labels: ${ steps.meta.outputs.labels } # docker run in server - name: Deploy uses: appleboy/ssh-action@master with: host: $ # EC2 인스턴스 퍼블릭 DNS username: ubuntu key: $ # pem 키 script: | docker pull $-$ docker stop demo docker rm demo docker run --restart always -d -p 80:8080 --name demo $-$" }, { "title": "HTTPS", "url": "/posts/HTTPS/", "categories": "데브옵스, 네트워크", "tags": "DevOps, Network, HTTPS", "date": "2023-01-04 13:00:00 +0900", "snippet": "HTTPS란웹 프로토콜 HTTPHTTP는 웹상에서 TCP 기반으로 정보를 주고받을 수 있는 웹 프로토콜입니다. 하지만 실제로 HTTP로 웹 통신을 하고 있을까요?실제로 HTTP로 웹 페이지를 배포하고 해당 웹 사이트에 접속을 해보면 아래처럼 꽤 무서운 문구들이 표시됩니다.이는 HTTPS를 사용하지 않아서 발생한 경고 메시지인데요. 그럼 HTTPS란 뭘까요?HTTPS아래는 HTTPS에 대한 위키백과의 정의입니다. HTTPS(HyperText Transfer Protocol over Secure Socket Layer, HTTP over TLS, HTTP over SSL, HTTP Secure)는 월드 와이드 웹 통신 프로토콜인 HTTP의 보안이 강화된 버전이다.HTTPS는 통신의 인증과 암호화를 위해 넷스케이프 커뮤니케이션즈 코퍼레이션이 개발한 넷스케이프 웹 프로토콜이며, 전자 상거래에서 널리 쓰인다. HTTPS는 소켓 통신에서 일반 텍스트를 이용하는 대신에, SSL이나 TLS 프로토콜을 통해 세션 데이터를 암호화한다. 따라서 데이터의 적절한 보호를 보장한다. HTTPS의 기본 TCP/IP 포트는 443이다. 보호의 수준은 웹 브라우저에서의 구현 정확도와 서버 소프트웨어, 지원하는 암호화 알고리즘에 달려있다. HTTPS를 사용하는 웹페이지의 URI는 ‘http://’대신 ‘https://’로 시작한다. 출처 : 위키피디아간단하게 얘기하면 HTTP에서 보안이 강화된 통신 방법이라고 볼 수 있습니다.그럼 어떻게 HTTPS가 어떻게 HTTP보다 안전하게 통신을 할 수 있게 되었는지 알아봅시다.HTTPS 통신 과정오브젝트 인증기관 (CA) 서버 클라이언트간략한 통신 과정서버 SSL 인증서 발행 서버는 한 쌍의 공개키와 개인키를 생성하고, 사이트의 정보와 자신의 공개키를 인증기관에 전달하여 SSL 인증서를 요청합니다. 인증기관은 SSL 인증서를 만들고, 자신의 개인키로 해당 인증서를 암호화하여 서버에게 전달합니다. 해당 인증서에는 서비스의 정보(인증서를 발급한 CA, 서비스의 도메인 등)와 서버의 공개키가 포함되어 있습니다. 서버는 전달받은 암호화된 SSL을 그대로 게시합니다.클라이언트 접속 클라이언트는 암호화 되어 있는 서버의 인증서를 인증기관의 공개키로 복호화하고 서버의 정보를 확인합니다. 서버의 정보를 확인할 수 있다면 해당 인증서는 실제 인증서입니다. 그리고 복호화를 통해 서버의 공개키 역시 알게 되었습니다. 클라이언트는 이제 서버를 신뢰하고, 해당 서버의 공개키로 대칭키인 세션키를 암호화하여 전송합니다. 서버는 자신의 개인키로 암호화되어 있는 클라이언트의 요청을 복호화하고 대칭키인 세션키를 저장합니다. 이후 대칭키 암호화 방식을 이용해 통신합니다.클라이언트 접속의 상세한 통신 과정클라이언트 접속은 실제로 SSL Handshake 과정을 거칩니다.1. Client Hello 클라이언트 -&gt; 서버 클라이언트가 서버에 연결을 시도하면서 헨드셰이크를 시작하는 패킷 내용 지원하는 TLS(SSL) 버전 랜덤 바이트 문자열 지원하는 암호 제품군 목록 (Cipher Suite) : SSL Protocol Version, Hash 방식 등의 정보가 담겨 있음 Image Reference : https://run-it.tistory.com/302. Server Hello 서버 -&gt; 클라이언트 Client Hello 메시지에 대한 응답으로 서버가 보내주는 패킷 내용 랜덤 바이트 문자열 선택한 암호 제품군 (Cipher Suite) : Client Hello에서 보내준 목록 중 하나를 선택함 3. Certificate 서버 -&gt; 클라이언트 Server Hello 패킷과 같이 자신의 인증서를 보내주는 패킷 내용 인증기관의 개인키로 암호화 되어 있는 SSL 인증서 SSL Protocol Version 4. Server Key Exchange 서버 -&gt; 클라이언트 만약 SSL 안에 서버의 공개키가 없다면, 직접 공개키를 보내준다. 내용 서버의 공개키 5. Verify server certificate 클라이언트가 서버의 SSL 인증서를 인증서 발행 기관(CA)의 공개키로 복호화하고 이를 검증합니다. 이를 통해 서버가 인증서에 명시된 서버인지, 클라이언트가 상호작용 중인 서버가 실제 해당 도메인의 소유자인지를 확인하고, 해당 서버의 공개키까지 갖게 되었습니다.6. Client Key Exchange 클라이언트 -&gt; 서버 클라이언트는 대칭키를 생성하여 서버의 공개키로 암호화하여 전송합니다. 해당 대칭키를 통해 실제로 암호화 통신을 진행합니다. 내용 암호화된 대칭키 7. Finished 서버 -&gt; 클라이언트 해당 패킷을 통해 SSL HandShake를 종료합니다. 이후 서버와 클라이언트가 갖게 된 대칭키를 통해 암호화된 통신을 주고받게 됩니다.HTTP와 HTTPS 성능일반적으로일반적으로 HTTP는 단순성 때문에 HTTPS보다 빠릅니다.당연하게도 HTTPS에는 SSL Hand Shake가 추가로 필요하기 때문이라고 볼 수 있죠.하지만 구글이 2012년 SPDY라는 새로운 네트워킹 프로토콜을 발표하고, 이를 통해 HTTP/2로 발전되면서 상황이 바뀌었습니다.다양한 웹 브라우저가 HTTP/2 지원을 추가하면서 암호화된 프로토콜에서만 HTTP/2가 작동할 수 있도록 구현했다고 합니다.또한 HTTP/2는 HTTPS를 위해 만들어진 것처럼 보이기도 합니다.HTTP/1.1의 plaintext 기반의 프로토콜은 HTTP/2에서 binary 기반의 프로토콜로 변경되었고, 한번 연결로 여러 번 통신하는 방식은 HTTP보다 HTTPS에서 더 효과적이기 때문입니다.테스트 결과그러나 아래 링크를 보면 HTTP보다 HTTPS가 더 빠르다고 합니다.HTTP vs HTTPS 속도 테스트왜 이런 결과가 나왔을까요?앞서 말했듯이 모든 브라우저에서 HTTP/2는 SSL/TLS에서만 지원한다고 했습니다.즉, 이 테스트는 실제로는 HTTP vs HTTPS가 아닌 HTTP/1.1 vs HTTP/2 로 볼 수 있습니다. 결과는 당연히 성능적으로 많은 부분이 개선된 HTTP/2의 압승이 되어버렸죠.실제로는실제로 요즘의 CPU는 HTTPS 프로토콜이 개발되던 때와는 비교가 안될 정도로 빨라졌습니다.따라서 오늘날의 두 프로토콜의 성능은 사실상 거의 차이가 없다고 봐도 무방합니다. -&gt; HTTPS는 안 쓸 이유가 없다.Referenceshttps://aws-hyoh.tistory.com/39https://ko.wikipedia.org/wiki/HTTPShttps://okky.kr/articles/480266https://ko.myservername.com/http-vs-https-an-depth-comparison-features)" }, { "title": "VPN", "url": "/posts/VPN/", "categories": "데브옵스, 네트워크", "tags": "DevOps, Network", "date": "2022-12-08 13:00:00 +0900", "snippet": "Private Network vs Public NetworkVPN에 대한 이해를 위해서는 먼저 사설망(Private Network)과 공중망(Public Network)에 대한 이해가 필요합니다. 사설망(Private Network) : 특정한 회사나 조직이 소유하고 독점적으로 사용하는 네트워크를 의미합니다. 공중망(Public Network) : 사설망과 반대되는 개념으로 불특정 다수의 사용자에게 서비스를 제공하는 통신망입니다.공중망은 어느 누구와 언제든 정보 교환이 가능하다는 특징 덕분에 연결성 측면에서 강점이 있지만 보안성이 취약하다는 단점이 있으며, 사설망은 그 반대로 연결성이 약하고 보안성이 강합니다.쉽게 말해서 예시를 들자면 우리가 가정에서 공유기 내부에서 사설 IP로 사용하고 있는 네트워크가 대표적인 사설망이라고 볼 수 있습니다.그리고 공중망은 인터넷이라고 볼 수 있죠.VPN 가상사설망VPN(Virtual Private Network, 가상사설망)은 인터넷과 같이 여러 사람이 공용으로 사용하는 공중망(Public Network)을 특정인이나 조직이 단독으로 사용하는 사설망(Private Network)처럼 동작시키는 것을 말합니다.특정 서버에 전용선을 구축하지 않고도 기존의 인터넷 회선을 빌려 안전하게 통신할 수 있도록 해줍니다.여기서 주목할 것은 Public Network를 Private Network처럼 활용할 수 있다는 점입니다.인터넷이라는 거대한 망을 터널을 뚫은 것처럼 통신한다 라는 의미로 VPN 터널링이라고도 합니다.VPN은 접속 형태에 따라 ‘Site-to-Client’과 ‘Site-to-Site’로 구분할 수 있습니다.자세한 건 아래 예시로 설명하겠습니다.예시로 설명~Private Network아래는 사설망을 가진 회사의 간단한 네트워크 구조도 입니다. VPN 설명을 위해 간략화 하였으니 참고해 주세요 :)해당 회사의 네트워크 보안 정책은 다음과 같습니다. Private Network는 각각 LAN으로 직접 연결되어 있음 외부 인터넷과는 차단되어 있음 서버는 회사 내 네트워크의 요청만 허용함보안적으로 완벽 합니다. 외부 인터넷과 차단되어 있기 때문에 불특정 다수의 공격을 1차적으로 막을 수 있겠죠.그렇게 모든 직원들은 출근을 하고 사무실에서 지정된 컴퓨터로 마음 편하게 작업을 하면 됩니다.재택근무 Site-to-Client VPN재택근무를 하라고 합니다. 위와 같은 구조에서 재택 근무가 가능 할까요?회사 네트워크 입장에서 외부인 집 PC에서는 내부망의 트래픽만 허용하는 보안 정책 상 네트워크 요청이 거절될 수 밖에 없습니다.여기서 선택지를 3가지로 추려보겠습니다. 직원 집의 PC까지 LAN선을 설치해 직접 연결한다. 보안 정책을 바꿔 외부 인터넷의 요청을 허용한다. Site-to-Client VPN을 이용한다.1번은 비용이 많이 들고, 2번은 보안상 너무 큰 리스크가 있기 때문에, 정답은 3번을 이용해야 합니다.실제로도 Site-to-Client VPN을 통해 재택 근무를 진행하는 회사가 많습니다.SSL VPNSite-to-Client 방식의 대표적인 VPN은 SSL VPN입니다. SSL(Secure Socket Layer) VPN의 정의는 아래와 같습니다.‘장소나 단말의 종류와 관계없이 내부 네트워크에 접속할 수 있는 SSL 기반의 가상 사설망(VPN)’HTTPS 통신에도 사용되는 SSL은 웹 브라우저와 서버 간의 통신에서 정보를 암호화함으로써 도중에 해킹을 통해 정보가 유출되더라도 정보의 내용을 보호할 수 있는 기능을 갖춘 보안 솔루션입니다.SSL VPN 환경이 구축되어 있으면, 언제 어디서든 외부에서 인터넷으로 내부 네트워크로 접근할 수 있습니다. 마치 내부 네트워크에 접속해 있는 것처럼 이용하죠.그럼 SSL VPN의 동작 원리를 알아봅시다. 서버에는 SSL VPN 장비를, 클라이언트 PC에는 전용 Agent 프로그램(브라우저도 가능)을 설치하는 등의 환경을 구축합니다. 외부의 클라이언트는 인터넷 브라우저나 전용 Agent 프로그램을 이용해 SSL VPN 장비의 public IP로 접속하여 로그인을 요청합니다. IP Pool에 해당 클라이언트의 IP를 저장하고 내부망의 IP주소를 할당해 줍니다. 클라이언트는 두 개의 IP 주소를 가지게 되며, 내부 사설망으로 향하는 접속이 있다면 VPN 터널링을 수행하고, 향하지 않는 접속은 기존과 같이 사용자 PC의 라우팅을 따릅니다. 내부 사설망으로 요청이 오면 저장해 둔 라우팅 테이블 정보에 따라 내부 네트워크에 접속되어 있는 IP로 인식하며 동작합니다. 서버의 응답은 VPN 장비가 받고 해당 값을 요청한 클라이언트에 전달합니다.회사 내부에 설치된 VPN 장비가 IP Pool에 각 IP 정보를 저장하고 프록시처럼 동작하는 걸 볼 수 있습니다.서버 입장에서는 클라이언트 PC가 내부 네트워크에서 요청하고 응답을 받아가는 것 처럼 보이겠죠?2번의 로그인 과정에서 ID/PW를 이용하거나 OTP, 공인인증서 등을 활용할 수도 있습니다.또한 SSL VPN의 주요 장점 중 하나는 최신 웹 브라우저에 구현된 TLS 기술을 사용하므로 특정 클라이언트 소프트웨어를 설치할 필요가 없다는 것입니다.타 네트워크 연결 - Site-to-Site VPN이번에는 외부에 있는 다른 Private Network와 통신을 하려고 합니다.Public Network를 통해 통신해도 되겠지만 외부에 노출되기 때문에 보안적으로는 좋은 선택지는 아닐 것입니다.사실 해당 요구사항에 대한 해답은 여러개가 존재하지만 해당 포스트에서는 Site-to-Site VPN을 이용하여 해결해 봅시다.IPsec VPNSite-to-Site VPN 방식의 대표적인 VPN은 IPsec VPN 입니다.외부에 있는 네트워크와 우리 회사의 Private Network를 IPsec(Internet Protocol Security)으로 암호화하여 터널링 통신으로 연결하는 서비스 입니다.해당 VPN 환경이 구축되어 있으면, 허가된 네트워크는 언제든지 기업 내 사설 네트워크에 보안 처리된 방식으로 안전하게 접속할 수 있습니다.IPsec VPN은 SSL VPN 방식과 달리 두개의 VPN 장비가 필요합니다. 서버 별로 프록시 서버처럼 동작하는 오브젝트가 하나씩 존재한다고 이해하셔도 좋습니다.IPsec은 두 가지의 모드를 지원하며 대부분 터널 모드를 사용합니다. (위 그림은 터널 모드) 전송 모드(Transport Mode) : IP 페이로드만 암호화, IP 헤더는 변경하지 않음 터널 모드(Tunnel Mode) : IP 패킷을 모두 암호화하고 새로운 Public IP 헤더를 추가함Image Reference : https://commons.wikimedia.org/위 모드 등에서 IP 패킷을 변경하는 방식은 IPsec 프로토콜 종류에 따라 결정됩니다.종류에 따라 IP 패킷에 아래와 같은 헤더를 추가함으로써 인증/암호화 하여 인터넷 프로토콜의 취약점을 보완합니다. IKE(Internet Key Exchange) : 통신 중인 호스트 간 SA를 확립하고, 통신 세션 과정에 사용할 암호 키와 알고리즘을 협상한다. AH(Authentication Header) : AH는 전송하는 패킷에 헤더 필드를 추가한다. 헤더 필드에는 패킷 내용이 암호화된 해시가 포함되어 있다. 패킷을 수신하는 호스트는 해당 해시를 이용해 페이로드가 전송 도중에 변경되지 않았음을 확인할 수 있다. ESP(Encapsulating Security Payload) : 페이로드를 암호화하고 패킷 헤더에 순차적으로 번호를 부여한다. 수신 호스트는 패킷 헤더에 부여된 번호로 중복 패킷이 아님을 확인할 수 있다.그렇다면 VPN우회의 원리는?위의 내용을 이해했다면 VPN을 사용했을 때 항상 특정 서버를 거쳐서 통신한다는 것을 알 수 있습니다.종종 인터넷을 이용하다가 warning.go.kr의 페이지를 가는 이유는 국가가 해당 도메인(=홈페이지)를 검열하기 때문인데요.VPN 우회를 하게되면, 다른 지역, 다른 나라의 네트워크망을 거쳐서, 또는 거치는 것 처럼 꾸밀 수 있기 때문에 해당 검열을 피할 수 있게 되는 것이죠.References https://sangbeomkim.tistory.com/135 https://guide.ncloud-docs.com/docs/security-security-5-1 https://ko.wikipedia.org/wiki/가상사설망" }, { "title": "Intellij Jira 연동", "url": "/posts/intellij-jira/", "categories": "팁, 인텔리제이", "tags": "IntelliJ, Jira", "date": "2022-12-05 13:00:00 +0900", "snippet": "1. Jira Api Token 발급 계정관리 → 보안 → API 토큰 만들기 및 관리 → 토큰 만들기 → 토큰 복사2. 인텔리제이 Jira 연동 shift shift 전체 검색 → configure servers + 버튼 → Jira → 입력값 입력 Search 내용에 따라 이슈가 필터링 됨3. 브랜치 네이밍 설정 Preferences → Tools → Tasks → Feature branch name format 수정+ 이슈 진행중 처리 및 브랜치 생성 opt + shift + n → 이슈 검색 및 선택 변경할 상태 선택, 브랜치 명 확인 인텔리제이 오른쪽 위에서도 확인 가능" }, { "title": "AWS Industry Week 2022 참여 후기", "url": "/posts/AWS-Industry-Week/", "categories": "후기, 컨퍼런스", "tags": "AWS, 컨퍼런스", "date": "2022-11-27 13:00:00 +0900", "snippet": "AWS Industry Week이번달 초 코엑스에서 열린 AWS Industry Week에 다녀왔습니다.회사에서 보내줬던 거라 더 즐거웠는데요.ㅎㅎ1년에 한 번 진행하는 컨퍼런스라 생각했던 것 보다 규모가 커서 놀랐습니다.천천히 하나씩 후기를 풀어보죠!체험 부스입장은 12시부터 가능하고 컨퍼런스는 2시부터 시작되는 일정이었는데요. 우선 저희는 12시쯤 도착해서 사람이 몰리기 전에 부스를 먼저 돌고 식사를 하기로 했습니다.체험 부스는 10개 미만 정도로 크진 않았습니다. 보통 어떻게 AWS에서 아키텍처를 구상하였는지, 어떤 서비스를 사용하였는지 등에 대한 내용이었습니다.선물 증정 이벤트도 많아서 여러 체험도 하고 궁금한 것도 질문하면서 돌아다니다 보니 금방 1시간이 금방 지나갔던 것 같습니다.저는 당연히 소프트웨어 쪽만 생각하였는데 제조/공정 분야도 참여도 있었기 때문에 스마트 팩토리와 로봇 분야도 AWS를 활용하여 간단한 공정을 구현해 낸 부스도 있어서 신기했었네요.컨퍼런스아래와 같은 순서 중 저는 ‘금융 및 핀테크’ 분야를 쭉 봤습니다.1. 잘 알수록 더 쉬워지는 금융 클라우드의 규제와 이용 [AWS]사실 발표 주제부터 굉장히 어렵고 무거워 보였는데요. 실제로도 그랬습니다 ㅎㅎ저희 회사에서는 완전히 은행 업무와 가깝다고 할 수는 없어서 어떻게 보면 상관이 없는 내용이었습니다.그래도 실제 금융 분야에서는 얼마나 보안에 대해 규제가 심하고 이를 맞추기 위해서 어떤 노력들이 필요한지에 대해 느껴볼 좋은 기회였던 것 같습니다.그리고 이 규제들은 굉장히 자주 바뀌기 때문에 이러한 것들을 그때그때 맞추기 서버 개발자와 데브옵스 개발자들이 여러 노력을 하고 있다는 것도 새삼 대단하게 느껴졌구요.그리고 금융 회사에서는 보통 전산실을 따로 두고 있어서 이를 클라우드로 이전하는 것도 보통 일이 아니라고 하는데,어떻게 하면 성공적으로 이전할 수 있는지 예시를 들어가며 설명을 해주셨습니다.이 역시도 규제와 금융감독원에 철저히 보고를 해야 하는 등 기술적인 이슈 외에도 다양한 이슈가 있기 때문에 거의 전 직무가 집중을 해야하는 일이라고 합니다 ㄷㄷ성공적으로 이전하고 이전 서버와 데이터에 대한 파기도 철저한 규제 정책에 따라 완수해야 하구요.당장 저와는 상관없는 내용이 대다수였지만 금융, 핀테크가 얼마나 무거운 분야인지 새삼 느낄 수 있었던 것 같습니다.2. 마이데이터 사업자로서의 AWS 인프라 구축 및 고도화 사례 [핀다]핀다라는 서비스는 많이 들어본 서비스여서 시작 전부터 관심이 갔었던 시간이었습니다.해당 세션에서는 핀다의 성장과 함께 어떻게 인프라를 고도화시켰는지, AWS와 금융규제 관점에서 풀어주셨어요.인프라 계정은 어떤 식으로 고도화하였고, 보다 안전한 네트워킹을 위해 어떤 전략을 사용하였는지, 로그는 어떤 식으로 통합하여 관리하게 되었는지 등의 내용이었습니다.기억에 남는 내용은 AWS Well-Architected Framework 에 관한 내용이었는데요.해당 서비스는 클라우드에서 아키텍처에 관한 모범사례 및 지침을 설명한다고 합니다.다양한 도메인에 해당하는 렌즈를 통해 모범사례를 찾아보고 WA Tool을 통해 내 아키텍처를 평가받을 수도 있다고 합니다.간단히 말하면 좋은 아키텍처의 예시를 볼 수 있고, 질문지도 제공하며, 평가까지 받아볼 수 있다는 얘기죠.인프라 아키텍처는 알면 알수록 굉장히 어려운 분야라고 생각하는데, 이렇게 모범사례나 테스트할 수 있는 도구가 제공된다면 보다 효율적이고 안정적으로 인프라를 구축할 수 있을 것 같네요.물론 돈은 나가겠지만… 크흠..3. 금융 혁신을 위한 코어시스템 현대화 전략 및 사례 [AWS]세번째 세션에서는 금융 시스템의 코어 시스템이 왜 레거시로 계속 남아있을 수밖에 없는지에 대해 설명하고, 이를 현대화하기 위한 노력을 왜 해야 하는지에 대해 설명하는 자리였습니다.알고 있었던 내용이지만 간단히 말하면, 금융 서비스의 코어 서비스는 직접적인 돈과 연관되어 있어서 괜히 건드리다가 조그만 문제라도 큰 파장을 일으키기 때문에 위험부담이 너무 큽니다.따라서 굉장히 오래된 언어와 프레임워크로 이뤄진 경우가 많다고 합니다.이를 개선하기 위해 전 세계의 금융사가 어떤 방법을 채택하여 현대화를 성공적으로 진행하였는지 실제 은행사의 이름까지 언급하며 좋은 사례들을 보여주셨습니다.4. KB 국민카드의 앱 모더나이제이션 여정 [KB 국민카드]세 번째 세션에 이어 네 번째 세션도 금융사의 현대화에 관한 내용이었지만, 이번에는 우리에게 친숙한 KB 국민은행의 사례였습니다.소위 말해 어떤 식으로 삽질을 하셨고, 어떻게 발전시켰는지에 대한 내용이었는데 덤덤하게 얘기하시지만 엄청난 노력이 들어갔다는 느낌을 충분히 받을 수 있었습니다.우선 금융사에서 쿠버네티스를 사용한다는 점도 흥미로웠다. 앞서 말한 것처럼 신기술(?)에 대한 도입은 꺼릴 것 같았는데, 비교적 새로운 서비스인 k8s를 사용하더군요.그리고 어떻게 온프레미스에서 클라우드로 이전하였는지, 이를 위해 비용관리를 어떤 식으로 하는지 등에 관한 내용을 들을 수 있었습니다.마지막엔 얼마나 성능 개선이 되었는지 실제 데이터를 보여주신 것도 흥미로웠고, 그걸 설명하시는 연사님의 자부심도 느낄 수 있었습니다.5. 당근페이의 AWS를 활용한 인프라 구축 사례 [당근마켓]당근마켓. 확실히 사람들이 엄청나게 몰렸습니다.당근마켓 세션은 비교적 가벼운 주제를 깊게 설명하였는데, 당근페이 서비스의 아키텍처를 구성할 때 어떤 고민을 하였고 왜 이런 선택을 했는지에 대한 내용이었습니다.당근페이 인프라는 전부 AWS에서 구현이 되었는데, 가장 많이 질문을 받았던 4가지에 대한 답변으로 이루어졌습니다. 개발/운영 환경 분리는 어떻게 했는지 서버 접근은 어떻게 했는지 모니터링 시스템은 어떻게 구성했는지 외부와의 연동은 어떻게 구성했는지확실히 서비스를 만들면서 고민할 만한 실용적인 내용이었고, 금융&amp;핀테크 분야에 한정되지 않고 누구나 고민해 볼 법한 내용이라 다수의 사람에게 유익했던 내용이었던 것 같습니다.추후 해당 내용은 따로 정리해 볼까 합니다 :)6. 2022년 한 해 동안 금융 고객사들에게 가장 많은 사랑을 받은 AWS 클라우드 서비스 [AWS]AWS에서 인기 있는 서비스를 소개하는 세션이었습니다.클라우드 구성에서의 VPC, Direct Connect, Transit Gateway가 소개되었고 기타 서비스로 EKS와 머신러닝 쪽 서비스가 소개되었습니다.마치며오프라인 컨퍼런스는 처음이었기에 꽤 즐겼던 것 같습니다. 회사에 적용할만한 직접적인 서비스는 별로 없었지만, 흥미가 가는 서비스도 많았고 이후 다양한 오프라인 세션에도 참여하고 싶은 마음이 생겼습니다.마지막으로 당일 받은 선물들과 핀다 강연자님의 마지막 말을 인용하며 끝내겠습니다. AWS를 온프라미스를 대체하는 인프라가 아닌, 다양한 서비스를 활용하시어 핀테크 규제 대응 및 신뢰성 있는 아키텍처 구현을 위한 전략적 플랫폼으로 활용하시기 바랍니다.Referenceshttps://aws.amazon.com/ko/events/industry-week" }, { "title": "AWS Athena 설정하기", "url": "/posts/AWS-Athena/", "categories": "데브옵스, AWS", "tags": "AWS, DevOps, Elastic Stack", "date": "2022-09-02 13:00:00 +0900", "snippet": "들어가며지난 포스트에서 Elastic Stack 로그 모니터링 환경에 대해 알아보았습니다.하지만… ELK를 구축하는 건 꽤 어렵습니다. 시간도 많이 들고, 서버 리소스도 많이 잡아먹습니다.시간적으로 보나 경제적으로 보나 비싸다는 얘기죠.고차원적인 로그 분석이 필요한 게 아니라면 사실 오버엔지니어링이 될 가능성이 있습니다.그럼 설치가 훨씬 쉽고, 별도의 서버 구축도 필요 없고, 가격까지 착한 서비스가 있다면 어떨까요?AWS AthenaImage Reference: https://aws.amazon.com/ko/trademark-guidelines/ Amazon Athena는 표준 SQL을 사용해 Amazon S3에 저장된 데이터를 간편하게 분석할 수 있는 대화식 쿼리 서비스입니다.Athena는 서버리스 서비스이므로 관리할 인프라가 없으며 실행한 쿼리에 대해서만 비용을 지불하면 됩니다.AWS Athena의 가장 중요한 키포인트는 ‘서버리스 서비스‘라는 것입니다.서버가 따로 돌아가지 않기 때문에 운영 비용이 들지 않고, 조회할 때마다 요금이 발생하는 방식입니다.심지어 그 금액도 스캔한 데이터의 TB당 5.00 USD(2022년 8월 기준)로 굉장히 저렴합니다.요금 링크아래는 AWS에서 설명하는 Athena의 이점입니다. 요약한 내용이며 자세한 내용은 여기를 눌러주세요. Start querying instantly Athena는 서버리스 서비스입니다.Amazon S3에 저장된 데이터를 지정하고 스키마를 정의한 다음 기본적으로 제공되는 쿼리 편집기를 사용해 쿼리를 시작하면 됩니다. Pay per query Amazon Athena에서는 실행한 쿼리에 대한 비용만 지불합니다.데이터를 압축 및 파티셔닝하고 컬럼 형식으로 변환함으로써 쿼리당 비용을 30%에서 90% 절감하고 성능을 더 향상할 수 있습니다. Open, powerful, standard Amazon Athena는 ANSI SQL을 지원하는 Presto를 사용하며, CSV, JSON 등 다양한 표준 데이터 형식과 호환됩니다.Athena는 대화형 쿼리에 적합하며 대용량 조인, 윈도 함수, 어레이 등 복잡한 분석을 처리하는데도 손색이 없습니다. Fast, really fast Amazon Athena에서는 빠른 속도의 대화식 쿼리 성능을 구현하기 위해 컴퓨팅 리소스가 충분한지 걱정할 필요가 없습니다.Amazon Athena는 병렬 방식으로 쿼리를 자동 실행하기 때문에 대부분 결과가 수 초 만에 반환됩니다. 그럼 AWS Athena 환경 구축을 직접 해보며 얼마나 간단한지 확인해 봅시다.Athena 설정하기 해당 포스트에서는 S3 버킷에 ELB의 Access Log가 수집되고 있음을 가정하고 AWS Athena 설정 방법을 설명합니다.1. IAM 권한 설정AWS Athena 콘솔을 사용하기 위해서는 추가적인 IAM 권한 설정이 필요합니다.아래의 두 가지의 정책을 기본으로 하며 별도로 수정도 가능합니다.자세한 내용은 AWS Athena IAM 공식문서를 참고해 주세요.AWSQuicksightAthenaAccessAmazon QuickSight와 Athena의 통합에 필요한 작업에 대한 액세스 권한을 부여 athena : Athena 리소스에 대한 액세스를 허용. glue : AWS Glue 데이터베이스, 테이블 및 파티션에 대한 액세스를 허용. s3 : Amazon S3에서 쿼리 결과를 읽고 쓰거나, Amazon S3에 상주하는 공개적으로 사용할 수 있는 Athena 데이터 예제를 읽거나, 버킷을 나열할 수 있도록 허용. lakeformation : 보안 주체가 Lake Formation에 등록된 데이터 레이크 위치의 데이터에 액세스하기 위해 임시 자격 증명을 요청하도록 허용.AmazonAthenaFullAccessAthena에 대한 완전한 액세스 권한 부여 sns : Amazon SNS 주제를 나열하고 주제 속성을 가져올 수 있도록 허용. 이를 통해 모니터링 및 알림 목적으로 Athena에 Amazon SNS 주제를 사용할 수 있음. cloudwatch : 보안 주체에게 CloudWatch 경보의 생성, 읽기 및 삭제를 허용. +AWSQuicksightAthenaAccess 정책 전부2. S3 설정Athena의 검색 대상이 될 S3를 지정합니다. 해당 S3의 prefix를 입력하고 저장 버튼을 눌러줍니다.여기서 Athena와 S3의 리전은 같아야 합니다.쿼리편집기 → 설정 → 관리 → 쿼리 대상 S3 버킷 저장3. 데이터베이스, 테이블 생성편집기에서 아래의 쿼리문을 통해 데이터베이스와 테이블을 생성합니다.쿼리문 제일 마지막에 있는 location 부분에 S3 환경에 맞추어 수정하고 실행합니다.CREATE EXTERNAL TABLE IF NOT EXISTS elb_log ( type string, time string, elb string, client_ip string, client_port int, target_ip string, target_port int, request_processing_time double, target_processing_time double, response_processing_time double, elb_status_code string, target_status_code string, received_bytes bigint, sent_bytes bigint, request_verb string, request_url string, request_proto string, user_agent string, ssl_cipher string, ssl_protocol string, target_group_arn string, trace_id string, domain_name string, chosen_cert_arn string, matched_rule_priority string, request_creation_time string, actions_executed string, redirect_url string, lambda_error_reason string, target_port_list string, target_status_code_list string, classification string, classification_reason string ) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe' WITH SERDEPROPERTIES ( 'serialization.format' = '1', 'input.regex' = '([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*):([0-9]*) ([^ ]*)[:-]([0-9]*) ([-.0-9]*) ([-.0-9]*) ([-.0-9]*) (|[-0-9]*) (-|[-0-9]*) ([-0-9]*) ([-0-9]*) \\\"([^ ]*) ([^ ]*) (- |[^ ]*)\\\" \\\"([^\\\"]*)\\\" ([A-Z0-9-]+) ([A-Za-z0-9.-]*) ([^ ]*) \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" ([-.0-9]*) ([^ ]*) \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" \\\"([^ ]*)\\\" \\\"([^\\s]+?)\\\" \\\"([^\\s]+)\\\" \\\"([^ ]*)\\\" \\\"([^ ]*)\\\"') LOCATION 's3://&lt;s3 위치&gt;/AWSLogs/&lt;계정 ID&gt;/elasticloadbalancing/&lt;region 위치&gt;/'; -- 설정 필요4. 데이터 조회자! 이렇게 AWS Athena 환경 구축이 완료되었습니다.간단하게 최근 10개 데이터만 조회하는 쿼리문을 실행하여 Athena 환경 구축이 잘 되었는지 확인해 봅시다.-- 최근 10개 로그 조회SELECT * FROM elb_log ORDER by time DESC LIMIT 10;5. 조회 결과위 사진에서의 제 환경은 약 2년 정도의 로그가 있었습니다.그리고 사진 우측 아래를 보면 실행시간이 21초나 되고 스캔한 데이터도 2.6GB나 됩니다.생각보다 성능이 아주아주 안 좋습니다. 겨우 10개의 로그 데이터를 요청한 건데 말이죠.파티션 프로젝션위와 같은 결과가 나온 이유는 Athena가 ‘모든 로그데이터’를 스캔하고 그중 10개의 데이터를 반환해서 이러한 현상이 발생한 것입니다.AWS는 이를 해결하기 위해 파티션을 설정할 수 있도록 하여 스캔해야 하는 데이터의 범위를 줄일 수 있도록 하였습니다.앞서 말했듯 AWS Athena의 과금 정책은 스캔한 데이터의 양만큼 청구됩니다.또한 해당 데이터양은 응답 속도에도 영향을 주기 때문에 스캔해야 하는 데이터가 줄이는 것이 필수적입니다.데이터를 줄임으로써 성능도 올리고 비용도 절감할 수 있는 아주 고마운 친구죠.그럼 거의 필수라고 할 수 있는 이 파티션 설정을 해봅시다.1. 테이블 생성우선 테이블부터 다시 만들어야 합니다. 아래의 쿼리문을 통해 새로 만들어 줍니다.해당 쿼리문을 통해 테이블을 생성하면 year, month, day 컬럼이 추가되어 데이터가 생성됩니다.CREATE EXTERNAL TABLE IF NOT EXISTS elb_log_partition_projection ( type string, time string, elb string, client_ip string, client_port int, target_ip string, target_port int, request_processing_time double, target_processing_time double, response_processing_time double, elb_status_code string, target_status_code string, received_bytes bigint, sent_bytes bigint, request_verb string, request_url string, request_proto string, user_agent string, ssl_cipher string, ssl_protocol string, target_group_arn string, trace_id string, domain_name string, chosen_cert_arn string, matched_rule_priority string, request_creation_time string, actions_executed string, redirect_url string, lambda_error_reason string, target_port_list string, target_status_code_list string, classification string, classification_reason string ) PARTITIONED BY(year int, month int, day int) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe' WITH SERDEPROPERTIES ( 'serialization.format' = '1', 'input.regex' = '([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*):([0-9]*) ([^ ]*)[:-]([0-9]*) ([-.0-9]*) ([-.0-9]*) ([-.0-9]*) (|[-0-9]*) (-|[-0-9]*) ([-0-9]*) ([-0-9]*) \\\"([^ ]*) ([^ ]*) (- |[^ ]*)\\\" \\\"([^\\\"]*)\\\" ([A-Z0-9-]+) ([A-Za-z0-9.-]*) ([^ ]*) \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" ([-.0-9]*) ([^ ]*) \\\"([^\\\"]*)\\\" \\\"([^\\\"]*)\\\" \\\"([^ ]*)\\\" \\\"([^\\s]+?)\\\" \\\"([^\\s]+)\\\" \\\"([^ ]*)\\\" \\\"([^ ]*)\\\"') LOCATION 's3://&lt;s3 위치&gt;/AWSLogs/&lt;계정 ID&gt;/elasticloadbalancing/&lt;region 위치&gt;/'; TBLPROPERTIES ( 'has_encrypted_data'='false', 'projection.day.digits'='2', 'projection.day.range'='01,31', 'projection.day.type'='integer', 'projection.enabled'='true', 'projection.month.digits'='2', 'projection.month.range'='01,12', 'projection.month.type'='integer', 'projection.year.digits'='4', 'projection.year.range'='2020,2100', 'projection.year.type'='integer', \"storage.location.template\" = \"s3://&lt;s3 위치&gt;/AWSLogs/&lt;계정 ID&gt;/elasticloadbalancing/&lt;region 위치&gt;/${year}/${month}/${day}\" );2. 데이터 조회아래 쿼리문(예시)으로 특정 날짜에 대한 로그 데이터 10개를 조회해 봅시다.-- 2022년 7월 1일 10개 로그 조회SELECT * FROM elb_log_partition_projection WHERE year = 2022 and month = 7 and day = 1 LIMIT 10;3. 조회 결과아래의 이미지는 파티션을 설정하지 않은 테이블의 조회 결과입니다.확실히 파티션을 설정함으로써 쿼리 실행 시간과 스캔한 데이터의 양이 확연히 줄어든 것을 확인할 수 있습니다.또한 사진 우측에 날짜 정보에 대한 3개의 컬럼이 추가된 것을 볼 수 있습니다.해당 데이터를 통해 스캔할 데이터의 범위를 줄일 수 있게 된 것이죠. 추가로 파티션 프로젝션 설정값을 조정하여 테이블 생성 시 해당 테이블에 포함될 데이터의 조건을 걸어서 전체 데이터가 아닌 조건에 맞는 데이터만 추가되도록 설정할 수 있습니다.ex) 2020년 로그 테이블 설정 : ‘projection.year.range’=’2020,2020’마무리하며AWS Athena 구축은 ELK에 비하면 훠어어얼씬 간단한 편인 것 같습니다.쿼리문을 통해 검색한다는 점이 누군가에게는 단점이 될 수 있겠지만 사용할 줄만 안다면 큰 장점이 되기도 하고요.하지만 이름 그대로 AWS에서 제공하는 서비스이기 때문에 AWS에서만 사용이 가능하다는 큰 한계점이 있다는 점과,모니터링 툴로써는 기능이 거의 없다는 점이 확실한 단점이 될 것 같습니다.Athena는 간단하게 로그 분석이 필요할 때만 사용하면 좋을 듯합니다.서버리스 서비스이기 때문에 구축해 놓더라도 운영 요금이 들지 않기 때문에 무지성으로 구축하는 것도 괜찮을 수도…? ㅎㅎReferenceshttps://aws.amazon.com/ko/premiumsupport/knowledge-center/athena-analyze-access-logshttps://docs.aws.amazon.com/athena/latest/ug/partitions.htmlhttps://jojoldu.tistory.com/537https://aws.amazon.com/ko/blogs/korea/top-10-performance-tuning-tips-for-amazon-athena/https://medium.com/bunjang-tech-blog/aws-athena를-사용해서-s3-데이터-조회해보자-bb250f1c2b1fhttps://stackoverflow.com/questions/51761067/aws-athena-sql-query-error-with-timestamp" }, { "title": "Elastic Stack (ELK)", "url": "/posts/Elastic-Stack(ELK)/", "categories": "데브옵스, 네트워크", "tags": "AWS, DevOps, Elastic Stack", "date": "2022-08-15 13:00:00 +0900", "snippet": "로그 모니터링운영환경에 애플리케이션을 배포하고 서비스를 운영하다 보면 경험해보지 못한 오류를 마주치곤 합니다.우리는 이러한 상황에서 좀 더 효율적으로 오류를 분석하고 대응하기 위해 ‘로그’를 남겨 놓습니다.로그를 남기는 방법 또한 다양합니다. 시스템 로컬에 파일로 남기거나 특정 로그 서버를 설정하여 여러 대의 서버 로그를 한곳에서 볼 수도 있죠.텍스트 그 자체로 분석할 수 있겠지만 로그가 쌓이고 종류가 다양해지면서 이 상태로 분석하는 것은 거의 불가능에 가깝습니다.따라서 우리는 로그 파일을 모니터링할 솔루션이 필요하였고 그중 가장 흔하게 사용되는 것이 바로 오늘 알아볼 Elastic Stack(ELK)입니다.ELKImage Reference: https://www.elastic.co/brandELK란 Elasticsearch, Logstash, Kibana의 세 가지 인기 있는 프로젝트로 구성된 스택을 의미하는 약자입니다.모니터링 서비스에서 가장 많이 사용되는 방법 중 하나이며 사용자에게 모든 시스템과 애플리케이션에서 로그를 집계하고 이를 분석하며 애플리케이션과 인프라 모니터링 시각화를 생성하고, 빠르게 문제를 해결하며 보안 분석할 수 있는 능력을 제공합니다.심지어 오픈소스로, 무료로 사용할 수 있습니다. ELK와 비슷하지만 유료 서비스인 Splunk가 있습니다.E :: Elastic SearchImage Reference: https://www.elastic.co/brandElastic Search는 아파치 루씬 기반의 검색 및 분석 엔진입니다.자바, 닷넷(C#), PHP, 파이썬 등 수많은 언어로 이용할 수 있으며 오픈 소스입니다.또한 스키마에서 자유로운 JSON 문서를 지원하고 HTTP 웹 인터페이스 역시 지원합니다.Elastic Search는 사실 로그 분석용 도구는 아닙니다. 성능 짱짱인 랭킹 1위 검색엔진이죠.하지만 그만큼 성능과 확장성이 검증되었기 때문에 로그 모니터링에서의 검색엔진으로써도 활용되고 있습니다.로그 분석 외에도 Elastic Search는 아래와 같이 다양한 사례에 이용될 수 있습니다. 애플리케이션 검색 웹사이트 검색 엔터프라이즈 검색 로깅과 로그 분석 인프라 메트릭과 컨테이너 모니터링 애플리케이션 성능 모니터링 위치 기반 정보 데이터 분석 및 시각화 보안 분석 비즈니스 분석 Apache Lucene 자바 언어로 이루어진 정보 검색 라이브러리 오픈 소스 소프트웨어.전문 검색 색인 및 검색 기능을 필요로 하는 모든 응용 프로그램에 적합하지만 웹 검색 엔진 및 로컬 단일 사이트 검색 구현에서의 유용성으로 널리 알려져 있다.추천 시스템을 구현하는데 사용되곤 한다.출처 - 위키피디아L :: LogstashImage Reference: https://www.elastic.co/brandLogstash는 JRuby로 개발된 데이터 수집 엔진입니다.좀 더 길게 표현하면 다양한 소스로부터 동시에데이터를 수집, 전환하여 전송할 수 있도록 하는 오픈 소스 데이터 처리 파이프라인이라고 말할 수 있겠네요.시스템 로그, 웹 사이트 로그, 애플리케이션 서버 로그 등 다양한 형식의 로그 데이터 원본에서 비정형 데이터를 쉽게 수집할 수 있습니다.Elastic Stack에서는 검색 엔진인 Elasticsearch의 데이터 파이프라인으로써 로그 데이터를 인덱싱하여 전송해주는 역할을 담당합니다.K :: KibanaImage Reference: https://www.elastic.co/brandKibana는 Elasticsearch 데이터를 시각화하고 Elastic Stack을 탐색하게 해주는 데이터 시각화 플러그인입니다.수집한 로그를 더욱 쉽게 분석할 수 있도록 도와줍니다.간단하게 말하자면 HTML + Javascript GUI 엔진이라고 볼 수 있습니다.키바나(Kibana)의 경우 대체할 수 있는 소프트웨어로 그라파나(Grafana)가 있습니다.Image Reference: https://www.elastic.co/brandELK 동작 원리자, 그럼 ELK의 구성 요소를 살펴 보았으니 전체적인 동작 원리를 알아봅시다. Logstash - Data Processing 서버 내의 로그 등을 수집하여 데이터 변환, 인덱싱 이후 송신 Elastic Search - Storage 데이터 저장, 분석, 관리 Kibana - Visualize 대시보드, 그래프 등의 인터페이스 제공 및 접근 제어와 같은 추가 기능 제공 Elastic Stack지금까지 ELK에 대해 알아보았습니다. 그럼 제가 글의 첫 부분에서 언급한 Elastic Stack은 뭘까요?Elastic Stack은 ELK의 새로운, 개선된 이름입니다.시간이 지나면서 Elasticsearch, Logstash, Kibana의 앞 글자를 딴 ELK에 Beat 등의 서비스가 추가되었고,더 이상 머리글자를 따서 만드는 형식으로는 너무 길어지는 상황이 생겼죠.그래서 Elastic Stack이라는 이름이 나온 것입니다.이름이 변경된 이후 ELK 외의 여러 서비스가 출시되었고, 또 많은 회사가 실제 서비스에 적용하여 활용하고 있습니다. Beats 서버에 에이전트로 설치하여 다양한 유형의 데이터를 Elasticsearch 또는 Logstash에 전송하는 오픈 소스 데이터 수집기출처 - Elastic/beatsReferenceshttps://www.elastic.co/kr/what-is/elk-stackhttps://www.elastic.co/kr/kibanahttps://aws.amazon.com/ko/opensearch-service/the-elk-stack" }, { "title": "static 메소드 vs @component 메소드 (feat.싱글톤 패턴)", "url": "/posts/static%EB%A9%94%EC%86%8C%EB%93%9C-vs-component%EB%A9%94%EC%86%8C%EB%93%9C/", "categories": "backend, spring", "tags": "spring, java", "date": "2022-07-08 13:00:00 +0900", "snippet": "들어가며스프링 프로젝트를 하면서 공통 클래스(예를 들면 유틸 클래스)를 만들 때 보통 static 방식과 @Component방식을 자주 사용합니다.이번 포스트에서는 이 두 방식의 차이점과 장단점을 살펴보고 각각 어느 상황에 써야 더 효율적이고 스프링다운지 알아보도록 합시다.예시 상황예시로 상황을 그려봅시다. 스프링 프로젝트를 진행하면서 공통으로 사용할 클래스(예를 들면 util 함수)를 추가하고자 합니다.이 때 우리는 아래와 같이 간단하게 static 클래스를 통해 해결할 수 있습니다.public class StringUtil { public static String getOnlyNumerics(String str) { return str.replaceAll(\"[^0-9]\", \"\"); }}@Servicepublic class service { public void tmp() { System.out.println(StringUtil.getOnlyNumerics(\"hello 123 world\")); }}또는 @component 어노테이션을 붙혀 빈으로 등록하거나 static 클래스로 선언하는 방법이 있습니다.@Componentpublic class StringUtil { public String getOnlyAlphabet(String str) { return str.replaceAll(\"[^a-zA-Z]\", \"\"); }}@Servicepublic class service { @Autowired private StringUtil stringUtil; public void tmp() { System.out.println(stringUtil.getOnlyNumerics(\"hello 123 world\")); }}위에서 살펴본 두 방식은 생긴것도 다르지만 내부적으로는 훨씬 다릅니다.Static? Singleton? 싱글톤 패턴(Singleton Pattern)이란 인스턴스가 오직 하나만 생성되는 것을 보장하고 어디에서든 이 인스턴스에 접근할 수 있도록 하는 디자인 패턴 이다.(출처: 해시넷 위키)Singleton@Component 어노테이션을 통해 생성한 객체는 빈으로 등록되어 IoC 컨테이너에서 관리됩니다.그리고 스프링 컨테이너는 등록된 스프링 빈들을 모두 싱글톤으로 관리합니다.즉 @Component 어노테이션을 붙힌 클래스는 스프링의 싱글톤 패턴을 통해 관리된다는 의미가 됩니다.따라서 어디서든 접근 가능한 IoC 컨테이너에 저장이 되며 애플리케이션이 시작될 당시 최초로 한 번만 메모리에 할당됩니다.Staticstatic은 인스턴스 변수를 클래스 변수로 만들어 줍니다.이를 통해 클래스명.메소드명을 통해 해당 메소드에 접근할 수 있게 됩니다. 마치 클래스명.변수명 처럼 말이죠.static 키워드를 통해 생성된 정적 멤버들은 Heap영역이 아닌 Static 영역에 할당됩니다.해당 영역에 할당된 메모리는 모든 객체가 공유하여 하나의 멤버를 어디서든지 참조할 수 있는 장점을 가지지만Garbage Collector의 관리 영역 밖에 존재하기에 static영역에 있는 멤버들은 프로그램의 종료시까지 메모리가 할당된 채로 존재하게 됩니다.그렇기에 static을 너무 남발하게 되면 만들고자 하는 시스템 성능에 악영향을 줄 수 있습니다. static에 대해 좀 더 이해가 필요하면 여기에 간단히 정리가 되어있으니 참고해주세요~차이점 아래에서는 편의상 @Component 어노테이션 등으로 스프링 컨테이너에 등록한 빈(POJO)을 싱글톤이라고 명명합니다.실제로는 이 둘의 정의가 조금 다르니 꼭 참고하시길 바랍니다.1. 저장 방식싱글톤은 다른 인스턴스 클래스들과 마찬가지로 힙 영역에 저장됩니다.이를 통해 애플리케이션에서 필요할 때 마다 싱글톤 객체를 불러올 수 있다는 장점을 가집니다.하지만 static 클래스는 위에서 언급했듯 컴파일 시 스택에 할당됩니다.따라서 이를 JVM에서 접근하기 위해선 항상 새로 불러와야 하는 단점이 있습니다.2. 런타임 다형성static 키워드를 통해 정의한 정적 메소드는 컴파일시 해석되기 때문에 애플리케이션을 종료하기 전까지는 재정의할 수 없습니다.반면 싱글톤은 다른 기본 클래스와 마찬가지로 런타임 내에 재정의될수있습니다.쉽게 예제코드로 살펴봅시다.public class SuperUtility { public static String echoIt(String data) { return \"원본\"; }}public class SubUtility extends SuperUtility { public static String echoIt(String data) { return data; }}위와 같이 “원본”을 출력하는 SuperUtility.echoIt과 이를 상속받아 재정의하는 SubUtility.echoIt이 있습니다.그렇다면 SuperUtility.echoIt(\"입력\")의 출력값은 뭐가 될까요?정답은 “원본”이 됩니다. 반대로 SubUtility.echoIt(\"입력\")의 출력값은 “입력”이 됩니다.이와는 대조적으로 싱글톤 클래스는 런타임 다형성을 가진다고 하였습니다.이것도 예제코드로 살펴봅시다.public class MyLock { protected String takeLock(int locks) { return \"Taken Specific Lock\"; }}public class SingletonLock extends MyLock { // private constructor and getInstance method @Override public String takeLock(int locks) { return \"Taken Singleton Lock\"; }}@Testpublic void whenSingletonDerivesBaseClass_thenRuntimePolymorphism() { MyLock myLock = new MyLock(); Assert.assertEquals(\"Taken Specific Lock\", myLock.takeLock(10)); myLock = SingletonLock.getInstance(); Assert.assertEquals(\"Taken Singleton Lock\", myLock.takeLock(10));}위 테스트코드는 모두 통과합니다. 런타임 안에서 해당 메소드 내용이 변경된 것이죠.즉 싱글톤은 런타임 다형성을 가진다고 볼 수 있습니다.기타 차이점 변수 상태 싱글톤 클래스: 인스턴스 변수이므로 다른 객체와 마찬가지로 해당 변수 상태를 유지할 수 있음 static 클래스: 클래스 변수와 static 메소드만 가지므로 특정 상태를 가지지 않음 직렬화 싱글톤 클래스: 직렬화 가능 static 클래스: 직렬화 불가능 효율성 앞서 말했듯 static 클래스는 초기화가 필요하지 않습니다. 이 덕분에 컴파일 시 정적 바인딩을 통해 싱글톤보다 효율적이고 더 빠른 경향이 있습니다. 하지만 static 메소드는 객체보다 클래스와 더 밀접하다고 볼 수 있기 때문에 단위 테스트 시 mocking 하거나 dummy나 stub으로 덮어씌우는게 어려워진다는 문제가 있습니다. 싱글톤의 경우 느리더라도 필요할 때만 불러와 상태를 유지하며 사용할 수 있습니다. Conclusion여기에서 권남님이 정의해주신 말이 있다. static 함수 모음 클래스의 모든 함수는 인자가 동일할 경우 항상 동일한 결과를 리턴해야 한다. 이 규칙을 지킬 수 없으면 POJO Bean으로 만들라.즉 static은 외부 자원(예를 들면 데이터 베이스)에 하나도 의존하면 안된다는 것이다.그렇다면 가장 맨 처음 봤던 StringUtil 클래스는 static일까? 싱글톤일까?public class StringUtil { public String getOnlyNumerics(String str) { return str.replaceAll(\"[^0-9]\", \"\"); }}간단하게 위에서 언급한 정의대로 생각해보자. Q. StringUtil 내에 있는 메소드는 항상 동일한 결과를 반환하는가?A. Yes.따라서 해당 클래스는 static 클래스로 정의하는 것이 올바르다.다른 예시를 들어보자.public class Util { @Autowired private UserRepository userRepository; public boolean isEmailDuplicated(String email) { Optional user = userRepository.findByEmail(email).orElse(null); return (user == null); }}해당 클래스의 isEmailDuplicated 데이터베이스에서 해당 메일로 가입된 유저가 있는지 확인하는 메소드이다.너무 쉬운 예시인 듯 하지만 해당 메소드는 외부 자원인 데이터베이스에 저장된 값에 따라 결과값이 달라지므로 @Component 어노테이션을 통해 선언하는게 올바르다.Referenceshttps://www.baeldung.com/java-static-class-vs-singletonhttps://enterkey.tistory.com/300https://www.geeksforgeeks.org/difference-between-singleton-pattern-and-static-class-in-javahttps://okky.kr/article/291799http://kwon37xi.egloos.com/4844149https://stackoverflow.com/questions/13746080/spring-or-not-spring-should-we-create-a-component-on-a-class-with-static-meth" }, { "title": "IP 주소와 CIDR", "url": "/posts/IP-%EC%A3%BC%EC%86%8C%EC%99%80-CIDR/", "categories": "데브옵스, 네트워크", "tags": "DevOps, network", "date": "2022-06-23 21:16:00 +0900", "snippet": "네트워크를 만지다 보면 CIDR 개념을 자주 접하게 된다.풀어 쓰면 Classless Inter-Domain Routing 이며 말 그대로 클래스 없는 도메인간 라우팅 기법이라는 뜻이다.이를 이해하기 위해선 기본적인 IP 주소에 대한 지식이 필요하기 때문에 이번 포스트에서는 기본적인 IP 주소에 대한 지식부터 이를 통해 왜 CIDR이 나오게 되었는지에 대해 알아보자. 해당 포스트에서는 IPv4만을 다룬다.IP 주소IP 주소는 0.0.0.0 부터 255.255.255.255까지 표현 가능하다. 이는 10진수로 나타냈을 때이며 2진수로 변환하면 아래와 같다. 10진수 192.168.0.1 2진수 1100 0000 . 1010 1000 . 0000 0000 . 0000 0001IPv4는 8개의 비트로 이루어진 옥텟(octet) 4개로 이루어져 있으며 총 32개의 비트로 이루어진다. 이를 통해 총 2^32개 만큼 IP 주소를 할당할 수 있다. 1 octet = 8 bit = 1 byteIP 주소 = 4 byteIP 클래스IP 주소를 각각 용도에 따라 구분하기 위해 총 5개의 클래스로 나누었다. 클래스별 IP 대역은 아래와 같다. IP 클래스 시작 주소 끝 주소 용도 A Class 0.0.0.0 127.255.255.255 큰 규모의 네트워크 B Class 128.0.0.0 191.255.255.255 일반적인 규모의 네트워크 C Class 192.0.0.0 223.255.255.255 작은 규모의 네트워크 D Class 224.0.0.0 239.255.255.255 멀티캐스트용 E Class 240.0.0.0 255.255.255.255 기타 목적 그리고 아래에 표시한 각 클래스별 첫 번째 옥텟을 보면 왜 위와 같은 시작주소가 나오게 되었는지 알 수 있다. IP 클래스 첫 번째 옥텟 2진수 첫 번째 옥텟 10진수 구분 A Class 0000 0000 0 첫 번째 비트 0 B Class 1000 0000 128 처음 2비트 10 C Class 1100 0000 192 처음 3비트 110 D Class 1110 0000 224 처음 4비트 1110 E Class 1111 0000 240 처음 4비트 1111 네트워크 ID, 호스트 ID와 서브넷 마스크IP 주소는 사실 네트워크 ID와 호스트 ID가 합쳐진 것이다.그리고 이를 구분해주는 IP 주소와 비슷하게 생긴 주소가 있는데 이를 서브넷 마스크라고 하며,이것을 통해 두 개의 ID로 나누는 작업 그 자체를 서브네팅이라고 한다. 네트워크 ID 네트워크를 지칭하는 주소. 네트워크 주소가 동일한 네트워크를 로컬 네트워크라고 한다. 호스트 ID 하나의 네트워크 내에 존재하는 호스트를 구분하기 위한 주소. 로컬 네트워크를 구성하는 하나의 네트워크.아래는 IP 클래스별 약속한 서브넷 마스크 이다.간단하게 설명하면 2진수의 서브넷 마스크에서 1로 표시되는 부분은 네트워크 ID이고 0으로 표시된 부분은 호스트 ID이다.예를 들어 A 클래스의 서브넷 마스크는 255.0.0.0이다.맨 앞 옥텟이 모두 1이고 나머지는 0이기 때문에 1개의 옥텟이 네트워크 ID를 나타내고 나머지 3개의 옥텟이 호스트 ID를 나타낸다.또한 맨 앞 비트가 0으로 고정되어 있기에 0(0000 0000) ~ 127(0111 1111)까지 총 128개의 네트워크가 존재하고각 네트워크 1개마다 0.0.0 ~ 255.255.255 총 16,777,216(256 * 256 * 256)개의 호스트를 갖는다는 것을 알 수 있다. 정확하게는 호스트 ID가 모두 0인 것과 1인 것은 각각 네트워크 주소, 브로드캐스트 주소이므로 호스트 개수는 위에서 설명한 것 보다 적다.CIDR위에서 설명한 IP 클래스는 default 서브넷 마스크가 있어서 네트워크를 가변적으로 나눌 수 없었다.이를 해결하기 위해 나온 방식이 CIDR 이다.CIDR의 생김새를 보자192.168.0.3/20기존의 IP 주소에 ‘숫자’가 더해졌다.해당 숫자는 서브넷 마스크의 1 개수를 의미한다.즉 해당 위 주소의 서브넷 마스크는 아래와 같다.1111 1111 . 1111 1111 . 0000 0000 . 0000 0000즉 네트워크 ID와 호스트 ID가 각각 2개의 옥텟을 가짐을 의미한다.또한 아래의 경우도 가능하다. IP 주소: 192.168.0.3/2 서브넷 마스크: 1100 0000 . 0000 0000 . 0000 0000 . 0000 0000 네트워크 개수 = 2^2 호스트 개수 = 2^30CIDR은 초반에 언급했듯이 클래스 없는 도메인간 라우팅 기법이다.즉 클래스의 개념을 없애고 서브넷 마스크를 이용하여 네트워크의 영역을 보다 유연하게 나눌 수 있는 것이다.또한 CIDR은 한 번에 해당 네트워크를 파악하는데 도움을 주기도 한다.Referencehttps://github-wiki-see.page/m/mapc-team/document/wiki/네트워크—IPv4—IPv6-&amp;-서브넷https://www.guru99.com/ip-address-classes.html" }, { "title": "AWS ELB", "url": "/posts/AWS-ELB/", "categories": "데브옵스, AWS", "tags": "AWS, DevOps", "date": "2022-06-19 13:00:00 +0900", "snippet": "Elastic Load BalancerELB라고 불리기도 하는 이놈은 AWS에서 제공하는 로드밸런서 서비스 입니다. Load Balancing기능 뿐만 아니라 대상에 대한 헬스 체크(health-check), 고정 세션(sticky-session), SSL 등의 기능을 수행합니다. 추가로 ELB를 활용하여 트래픽 양에 따라 유동적으로 인스턴스 수를 조절해 주는 AutoSaciling 서비스를 이용할 수도 있습니다.종류ELB는 OSI 7계층에서 동작하는 위치에 따라 총 4개로 나뉩니다. (자세한 비교는 여기)Application Load Balancer (ALB) 7계층에 해당하는 Application Layer에서 동작한다. 일반적인 웹 서버의 경우 가장 일반적으로 사용된다. SSL 인증서를 추가할 수 있다. HTTP, HTTPS의 헤더 정보를 이용해 로드밸런싱을 진행한다.Network Load Balancer (NLB) 4계층에 해당하는 Transport Layer에서 동작한다. UDP를 사용하는 서버가 있다면 NLB를 고려해 보자 TCP, UDP…Classic Load Balancer (CLB) 4계층 또는 7계층에서 동작한다. 가장 기본적인 형태의 로드밸런서이며 EC2 Classic이 대상이다. 현재는 없어지는 추세이다.Gateway Load Balancer (GWLB) 3계층에 해당하는 Network Layer에서 동작한다. 네트워크 트래픽이 애플리케이션으로 이동하기 전에 모든 트래픽을 검사하기 위해 사용한다. 기존 3rd-party를 이용하여 방화벽을 구축하는 경우에 발생하는 운영 복잡도 증가 및 제약 사항에 대한 문제점들을 해결할 수 있다. 방화벽, 침입 탐지 및 방지 시스템, 심층 패킷 검사 시스템 등 보안과 관련된 작업을 수행할 수 있다. 2020년 11월에 출시되어 가장 최근에 생긴 로드밸런서이다.간단한 동작 과정 (ALB)실제로 사용자는 LB와 통신하게 됩니다. 마치 프록시 서버처럼 동작하는 것을 볼 수 있습니다. 대략적인 통신 과정은 아래와 같습니다. 사용자와 ALB의 3-way handshake ALB와 EC2 인스턴스의 3-way handshake 사용자가 ALB에 요청을 보내면 ALB가 EC2(그룹)에 전달 EC2의 응답을 사용자에게 전달 AWS-ACM 인증서 AWS에서 제공하는 무료 SSL 인증서 발급 서비스입니다. 자동적으로 인증서를 업데이트 해주며 ALB를 통해 배포한 웹 서비스에 HTTPS를 적용하기 위해 주로 쓰입니다. 추가로 인증서 발급을 위해선 유효한 도메인 주소가 있어야 하기 때문에 Route53과 함께 사용합니다.References로드 밸런서 유형 - https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/load-balancer-types.htmlELB - https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/userguide/what-is-load-balancing.html" }, { "title": "AWS Route53", "url": "/posts/AWS-Route53/", "categories": "데브옵스, AWS", "tags": "AWS, DevOps", "date": "2022-06-15 13:00:00 +0900", "snippet": "Route53Route53은 AWS에서 제공하는 DNS 서비스입니다. DNS 라우팅 뿐만 아니라 트래픽 관리, 모니터링 등의 기능을 수행할 수 있습니다. 도메인은 국내 도메인 제공업체(호스팅 케이알, 가비아 등)를 통해 등록하거나, 직접 AWS에서 발급받을 수 있습니다. (AWS-ACM 참고)호스팅 영역 :: hosted zone 호스팅 영역 1개는 도메인 1개와 같습니다. 퍼블릭 유형: 인터넷과 연결된, Public IP를 가진 서비스 대상 프라이빗 유형: Amazon VPC 내에 있는 서비스 대상 레코드 유형 :: record type A 타입: Address domain에 IPv4 주소를 할당하는 유형이다. huey-j.com - 111.222.333.0 CNAME 타입: Canonical name 다른 도메인 별칭(alias)을 부여한다. cname.huey-j.com NS 타입: Name Server Type AWS에서 자동 생성되며 필수값이다. NS는 총 4개로 구성되어 있는데, 이는 1개의 NS가 죽어 내 서비스에 접속이 불가능하게 되는 경우를 방지하기 위함이다. SOA 타입: Start Of Authority AWS에서 자동 생성되며 필수값이다. 해당 DNS 서버 자체의 설정 정보를 정의한다. 기타 유형ReferencesAmazon Route 53 개념 - https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/route-53-concepts.html레코드 작업 - https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/rrsets-working-with.html" }, { "title": "Git 커밋 컨벤션", "url": "/posts/Git-%EC%BB%A4%EB%B0%8B-%EC%BB%A8%EB%B2%A4%EC%85%98/", "categories": "Git", "tags": "Git, Convention", "date": "2021-11-29 13:00:00 +0900", "snippet": " 본 내용은 Udacity의 커밋 메세지 스타일 가이드를 참조하였습니다.커밋 메시지는 크게 제목, 본문, 꼬리말 세 가지 파트로 나누고, 각 파트는 빈줄을 두어서 구분합니다.제목 어떤 의도인지 짧게 설명 : 뒤에만 space가 있음 type: subjectType 기능 feat : 새로운 기능 추가 fix : 버그 수정 design : UI 디자인 변경 (css 등) 개선 style : 코드 수정 없음 (세미콜론 누락, 코드 포맷팅 등) refactor : 리펙토링 comment : 주석 추가 및 변경 기타 docs : 문서 수정 (README.md 등) test : 테스트 코드 추가 chore : 빌드 업무 수정, 패키지 매니저 수정 (pom.xml 등) rename : 파일명, 폴더명 수정 또는 이동 remove : 파일 삭제 Subject 동사 원형으로 시작 영어일 경우 첫 글자는 대문자 50자 이내로 작성 마지막에 특수문자 X (마침표, 느낌표 등)본문 (Body) 무엇을 왜 했는지 설명 한 줄 당 72자 이내로 작성 최대한 상세히 작성꼬리말 (Footer) 필수가 아닌 optional issue tracker ID를 명시하고 싶은 경우에 작성 유형: #이슈 번호 ex) Fixes: #23 유형 종류 Fixes: 이슈 수정중 (아직 해결되지 않은 경우) Resolves: 이슈를 해결했을 때 사용 Ref: 참고할 이슈가 있을 때 사용 Related to: 해당 커밋에 관련된 이슈번호 (아직 해결되지 않은 경우) Udacity 예시feat: Summarize changes in around 50 characters or lessMore detailed explanatory text, if necessary. Wrap it to about 72characters or so. In some contexts, the first line is treated as thesubject of the commit and the rest of the text as the body. Theblank line separating the summary from the body is critical (unlessyou omit the body entirely); various tools like `log`, `shortlog`and `rebase` can get confused if you run the two together.Explain the problem that this commit is solving. Focus on why youare making this change as opposed to how (the code explains that).Are there side effects or other unintuitive consequences of thischange? Here's the place to explain them.Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary hereIf you use an issue tracker, put references to them at the bottom,like this:Resolves: #123See also: #456, #789ReferencesUdacity Git Commit Message Style Guide" }, { "title": "장고 User Model 확장 (feat.AbstractUser)", "url": "/posts/%EC%9E%A5%EA%B3%A0-UserModel-%ED%99%95%EC%9E%A5/", "categories": "backend, Django", "tags": "django, python", "date": "2021-04-07 13:00:00 +0900", "snippet": "📢 시작하기 전에…🙄 확장이 왜 필요해?Django에는 권한 및 인증에 대한 기본적인 기능들을 제공하고 있는데요.사용자 정보가 담길 User Model 역시 이미 구현이 되어있기 때문에 쉽게 로그인 기능을 구현할 수 있습니다.하지만 실제 서비스에서 저장해야 하는 사용자 데이터들이 대부분 다르기 때문에 해당 기능들을 수정해야할 필요가 있습니다.이것 또한 Django에 준비가 되어있습니다.무려 수정이 필요한 정도에 따라 4가지로 구분되어서 말이죠..!이 4가지 방법에 대한 것은 요기에 제가 간단하게 정리했으니 확인하고 오셔도 좋습니다! 해당 글에서는 AbstractUser를 활용합니다. AbstractUser는 Django의 로그인 기능을 사용하면서 User Model의 칼럼(데이터)들을 수정할 수 있게 됩니다.🧐 현재 상황은 어떠신가요AbstractUser는 장고에서 기본적으로 제공되는 로그인 기능을 수정하는 것입니다.즉 User Model 역시 기본적으로 제공되어 자동으로 DB에 테이블을 만들기 때문에 Django가 이 테이블을 만들기 전(migrate 전)에! 작업을 해야합니다.그럼 이미 Django가 이미 테이블을 만들었는데 전 AbstractUser 사용 안되나요??!?!?!😱그래도 괜찮습니다. 당연히 프로젝트 초기에 하는게 깔끔하지만 방법은 있죠! 아래에 상황에 따라 구분지어서 진행할 것이니 잘 따라와 주세요! 기본적인 User Model   칼럼명 설명 필수여부 데이터타입 크기 1 id PK O int 11 2 username 이름(전체) O char 150 3 first_name 성 X char 30 4 last_name 이름 X char 150 5 email 이메일 X char 254 6 password 암호화된 비밀번호 O char 128 7 is_staff admin접속 가능 여부 O bool 1 8 is_activate 계정 활성 여부 O bool 1 9 is_superuser 모든 권한 활성 여부 O bool 1 10 last_login 마지막으로 로그인한 시간 O datetime 6 11 date_joined 계정이 생성된 날짜 O datetime 6 User Model 확장! 테이블 생성이 이미 되어 있다면 (migate를 이미 한 경우) 생성되어 있는 회원과 관련된 앱에 migrations폴더에서 __pycache__폴더와 __init__.py를 제외하고 다 지워주세요. DB에서 살려야할 데이터를 백업해 주신 다음 과감하게 DROP해 줍니다. 아래 작업을 한 다음 백업한 데이터를 새 DB에 넣어주시면 끝! 1. 우선 우리만의 User Model을 만들어 봅시다. accounts 앱 안에 있는 models.py에 다음을 추가해 주세요. 위에서 언급한 칼럼에서 사용하지 않을 데이터는 None으로 처리할 수 있습니다.(저는 앱 이름을 accounts, 모델 이름을 User로 했는데 바꾸셔도 됩니다:)from django.db import modelsfrom django.contrib.auth.models import AbstractUser\t# AbstractUser 불러오기class User(AbstractUser): test = models.CharField(max_length=20, default=\"\") test2 = models.CharField(max_length=20, null=True) first_name = None2. 이제 Django한테 우리가 User Model을 따로 정의했다고 알려줍시다. settings.py에 다음을 추가해 주세요.AUTH_USER_MODEL = 'accounts.User' accounts앱 폴더 안의 admin.py에 다음을 추가해주세요.admin 페이지에서도 확인할 수 있어야 하니까요from django.contrib import adminfrom .models import Useradmin.site.register(User)3. 그럼 DB를 생성해 볼까요? 콘솔창에 아래와 같이 실행해 줍니다.python manage.py makemigrationspython manage.py migrate4. 관리자계정을 만들고 생성된 DB를 확인해보세요!python manage.py createsuperuserpython manage.py runserver 완성입니다! 🎉이제 User Model의 데이터를 변경하면서 Django의 로그인 기능을 사용할 수 있게 되었습니다.👏👏👏👏 추가로 mysql을 사용하는 경우 한글을 저장할 때 charset 문제가 발생할 수 있으니 DB생성시 utf8로 꼭 설정해 주세요!" }, { "title": "장고 User Model 확장 방법", "url": "/posts/%EC%9E%A5%EA%B3%A0-UserModel-%ED%99%95%EC%9E%A5-%EB%B0%A9%EB%B2%95/", "categories": "backend, Django", "tags": "django, python", "date": "2021-04-06 13:00:00 +0900", "snippet": "‘User Model’이란?Django는 백엔드에서 꽤 중요한 부분을 차지하고 있는 권한과 인증에 대해 구현이 되어있습니다.이때 User Model이 사용자들의 데이터를 저장합니다.물론 제공되어 있는 그대로의 User Model을 사용해도 좋지만 서비스를 개발할 땐 더 다양한 기능과 정보들을 필요로 할 때가 많기 때문에 서비스를 개발 할 때 User Model을 그대로 사용하는 경우는 거의 없다고 합니다. 아래처럼 settings.py에 자동으로 적용되어 있다. INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.sessions', ...] User Model 확장 방법1. 프록시 모델 사용(Proxy Model) 테이블 추가, 변경 없이 단순히 상속만 하는 방식 정렬순서나 필요한 메소드만 추가하기 위해 사용 기존의 User Model에 추가적인 사용자 정보를 저장할 필요가 없을 때 사용하는 가장 간단한 방법class Profile(models.Model): user = models.OneToOneField(User, on_delete=models.CASCADE) user_pk = models.IntegerField(blank=True) nickname = models.CharField(max_length=200, blank=True) phone = models.CharField(max_length=200, blank=True) ...2. 일대일 연결(one-to-one) 모델(테이블)을 추가하여 기존 User Model과 일대일로 연결시켜서 사용자에 대한 정보를 저장 Django의 인증 시스템을 그대로 활용하고 로그인, 권한 부여 등과 상관이 없는 사용자 데이터를 저장하고자 할 때 사용하는 간단한 방법from django.db import modelsfrom django.contrib.auth.models import User class Profile(models.Model): user = models.OneToOneField(User, on_delete=models.CASCADE) user_pk = models.IntegerField(blank=True) nickname = models.CharField(max_length=200, blank=True) phone = models.CharField(max_length=200, blank=True) ...3. AbstractUser 모델 사용 AbstractUser Model을 상속한 User Model을 새로 정의하여 사용 (settings.py 수정 필요) 이 기법의 사용 여부는 프로젝트 시작 전에 하는 것이 좋음 기존의 User Model을 그대로 사용하므로 기본 로그인 인증 처리 부분은 Django의 것을 이용하면서 몇몇 사용자 정의 필드를 추가할 때 유리함from django.db import modelsfrom django.contrib.auth.models import AbstractBaseUserclass User(AbstractBaseUser, PermissionsMixin): objects = UserManager() email = models.EmailField(verbose_name = \"email id\", max_length = 64, unique = True) username = models.CharField(max_length=30) USERNAME_FIELD = 'email' date_joined = models.DateTimeField(_('date joined'), default=timezone.now) ...4. AbstractBaseUser 모델 사용 AbstractBaseUser Model을 상속한 User Model을 새로 정의하여 사용 (settings.py 수정 필요) 이 기법의 사용 여부는 프로젝트 시작 전에 하는 것이 좋음 로그인 아이디로 이메일 주소를 사용하도록 하거나 Django 로그인 절차가 아닌 인증 절차를 직접 구현하고자 할 때 사용 (가장 자유도가 높음)from django.db import modelsfrom django.contrib.auth.models import AbstractUserclass User(AbstractUser): bio = models.TextField(max_length=500, blank=True) location = models.CharField(max_length=30, blank=True) birth_date = models.DateField(null=True, blank=True) ..." }, { "title": "그래프와 DFS, BFS 정리", "url": "/posts/%EA%B7%B8%EB%9E%98%ED%94%84%EC%99%80-DFS-BFS-%EC%A0%95%EB%A6%AC/", "categories": "알고리즘", "tags": "알고리즘, 파이썬", "date": "2021-02-13 15:10:00 +0900", "snippet": "그래프 (Graph)그래프란? 여러 노드와 간선으로 연결된 네트워크 또는 자료구조 그래프(Graph)는 노드(Vertex)와 간선(Edge)으로 이루어짐 G = (V, E) 차수(Degree)는 해당 노드에 연결된 간선의 수그래프 종류 무방향 그래프 / 방향 그래프: 간선에 방향이 있거나 없음 가중치 그래프: 간선에 비용이 할당됨 완전 그래프: 모든 노드가 서로 연결됨 비연결 그래프 / 연결 그래프 순환 그래프 / 비순환 그래프들어가기 전 DFS vs BFS 간단비교이미지 출처깊이우선탐색 (Depth First Search) 한 노드의 자식을 끝까지 순회한 후 다른 노드 순회 자식 우선 스택(LIFO) 사용너비우선탐색 (Breadth First Search) 한 단계씩 내려가면서 같은 레벨에 있는 노드들을 먼저 순회 형제 우선 큐(FIFO) 사용깊이 우선 탐색 (DFS)DFS에서는 한 단계에서 Pop과 Extand를 수행 (LIFO) Pop: 스택의 맨 위 노드를 꺼냄 Extand: 지워진 노드의 자식들을 모두 스택에 넣음이미지 출처def DFS(start_node, target_node):\t# 1) stack 에 첫 번째 노드 넣으면서 시작\tstack = [start_node, ] \twhile True:\t\t# 2) stack이 비어있으면 종료\t\tif len(stack) == 0:\t\t\tprint(\"None\")\t\t\treturn None \t\t# 3) stack에서 맨 뒤의 노드를 pop\t\tnode = stack.pop()\t\t# 4) target_node를 찾으면 해당 노드 반환 (조건문은 상황에 따라 다름)\t\tif node == target_node:\t\t\tprint('The target found.')\t\t\treturn node\t\t# 5) node의 자식을 expand 해서 childrens에 저장\t\tchildrens = expand(node)\t\t# 6) childrens을 stack에 넣기\t\tstack.extend(childrens)넓이 우선 탐색 (BFS)BFS에서는 한 단계에서 Dequeue과 Enqueue를 수행 (FIFO) Dequeue: 큐의 맨 위 노드를 꺼냄 Enqueue: 지워진 노드의 자식들을 모두 스택에 넣음이미지 출처def BFS(start_node, target_node):\t# 1) queue 에 첫 번째 노드 넣으면서 시작\tqueue = [start_node, ]\twhile True:\t\t# 2) queue가 비어있으면 종료\t\tif len(queue) == 0:\t\t\tprint('None')\t\t\treturn None \t\t# 3) queue에서 맨 위의 노드를 dequeue (0번 인덱스를 pop)\t\tnode = queue.pop(0) \t\t# 4) target_node를 찾으면 해당 노드 반환 (조건문은 상황에 따라 다름)\t\tif node == target_node:\t\t\tprint('The target found.')\t\t\treturn node\t\t# 5) node의 자식을 expand 해서 childrens에 저장\t\tchildrens = expand(node)\t\t# 6) childrens을 queue에 넣기\t\tqueue.extend(children)요약 구분 DFS BFS 우선순위 자식먼저(깊게) 형제먼저(넓게) 자료구조 스택(LIFO) 큐(FIFO) 코드차이 (위 코드 기준) pop() pop(0) " }, { "title": "정렬 알고리즘 정리", "url": "/posts/%EC%A0%95%EB%A0%AC-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%A0%95%EB%A6%AC/", "categories": "알고리즘", "tags": "알고리즘, 파이썬", "date": "2021-02-04 13:00:00 +0900", "snippet": "정렬이란? 정렬 (sorting): 어떤 데이터들이 주어졌을 때 정해진 순서대로 나열하는 것 프로그래밍에서 자주 사용됨 정렬을 위한 다양한 알고리즘이 있음 +빅오 비교 (Big O) O(1) &lt; O(log n) &lt; O(n) &lt; O(n*log n) &lt; O(n^2) &lt; O(2^n) &lt; O(n!) 쉬운 설명을 위해 모든 예시는 오름차순 정렬을 사용함버블정렬 (Bubble sort) 인접한 두 데이터를 비교 앞에 있는 데이터가 뒤에 있는 데이터보다 크면 Swap! 시간복잡도: O(n^2)이미지 출처def bubbleSort(x): length = len(x)-1 for i in range(length): for j in range(length-i): if x[j] &gt; x[j+1]:\t\t# 앞에가 더 크면 Swap x[j], x[j+1] = x[j+1], x[j] return x삽입정렬 (Insertion sort) 앞에 있는 데이터들과 비교 비교할 데이터보다 작은 데이터가 나오는 곳에 Insert! O(n^2)이미지 출처def insert_sort(x): for i in range(1, len(x)): j = i - 1 key = x[i] while x[j] &gt; key and j &gt;= 0:\t#자신보다 크면 순서 바꾸기 x[j+1] = x[j] j = j - 1 x[j+1] = key\t\t\t# 반복문 멈춘 자리에 Insert return x선택정렬 (Selection sort) 데이터 중 최소값을 찾아 맨 앞과 Swap O(n^2)이미지 출처def selectionSort(x): length = len(x) for i in range(length-1): indexMin = i for j in range(i+1, length): if x[indexMin] &gt; x[j]: indexMin = j\t\t\t#최소값 찾기 x[i], x[indexMin] = x[indexMin], x[i]\t#맨 앞과 Swap return x병합정렬 (Merge sort) 재귀 활용 (분할 정복) &lt;-아래 설명 확인 절반으로 잘게 자르고 다시 합병하며 정렬 O(n*log n)이미지 출처def split(data_list): if len(data_list) &lt;= 1:\t#탈출: 더 자를수 없음 return data_list mid = len(data_list) // 2\t#가운데를 기준으로 나눠서 재귀 left = split(data_list[:mid]) right = split(data_list[mid:]) return merge(left, right)\t#병합def merge(left, right): merged = list() left_i, right_i = 0, 0 while left_i&lt;len(left) and right_i&lt;len(right): if right[right_i] &lt; left[left_i]: #left, right 중 작은 값 하나씩 추가 merged.append(right[right_i]) right_i += 1 else: merged.append(left[left_i]) left_i += 1 #남은 값들 추가 while left_i &lt; len(left): merged.append(left[left_i]) left_point += 1 while right_i &lt; len(right): merged.append(right[right_i]) right_i += 1 return merged퀵정렬 (Quick sort) 기준(pivot)을 잡고 해당 값보다 작은 값은 왼쪽, 큰 값은 오른쪽으로 Swap 기준을 잡는 방법은 다양함 O(n*log n) 정렬 알고리즘의 꽃 (이름부터 빨라)이미지 출처def quicksort(x): if len(x) &lt;= 1:\t\t#탈출: 더 자를 수 없음 return x pivot = x[len(x) // 2]\t#인덱스 기준 중간값을 기준점으로 less = [] more = [] equal = [] for a in x:\t\t\t#모든 값을 기준값과 비교해 3개의 그룹으로 나눔 if a &lt; pivot: less.append(a) elif a &gt; pivot: more.append(a) else: equal.append(a) return quicksort(less) + equal + quicksort(more)\t#재귀 및 병합* 동적 계획법 &amp; 분할 정복 추가로 알아보면 좋을 내용 :)a. 동적 계획법 (Dynamic Programming) 흔히 DP라고 불림 상향식 접근법: 최하위 해답을 구한 후 이를 이용해 상위 문제를 풀어가며 결국 전체 문제를 해결 Memoization 기법 사용: 이전에 계산한 값을 저장 피보나치 수열 등b. 분할 정복 (Divide and Conquer) 하향식 접근법: 문제를 최대한 나누어 풀고 다시 합병하여 전체 문제를 해결 Memoization 기법 사용 X 퀵 정렬 등" } ]
